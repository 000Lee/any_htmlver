{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9cd056-97ee-4ca0-829b-63e9a0e6683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 6587ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/6587] 20110217_LGì „ì G-TIPIS ë¶ê²½ ì¶œì¥ë¹„ ì‹ ì²­_2003007.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/6587] 20110329_2011ë…„ 3ì›” CARD ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ _ì´í˜•ê· _2003110.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/6587] 20110506_ì•ˆë…•í•˜ì„¸ìš” ì• ë‹ˆíŒŒì´ë¸Œì‹œìŠ¤í…œì˜ ê¹€í˜„ì¤‘ ì…ë‹ˆë‹¤ ì˜ˆë¹„êµ° í›ˆë ¨ìœ¼ë¡œ ì¸í•œ íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤_2003207.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/6587] 20110624_ì—°ì°¨ íœ´ê°€ í’ˆì˜_2003305.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/6587] 20110801_ì‚¼ì„±ì½”ë‹ ì¶œì¥ì‹ëŒ€(ì¡°_ì„ì‹) ì‹ ì²­(7_18~7_29)_2003407.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/6587] 20110926_[êµ¬ë§¤í’ˆì˜]ë…¸íŠ¸ë¶ êµ¬ë§¤-ì‹ ì…ì‚¬ì›(ê¹€í™˜ìš©, ë°•ìƒì•ˆ, ê¹€ë´‰ë¯¼)_2003506.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/6587] 20111101_í•œêµ­í•œì˜í•™ì—°êµ¬ì› - 2011ë…„ 10ì›” CARD ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (5021-2314-9982-6902)_2003607.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/6587] 20111206_êµ­ë‚´ì¶œì¥ë¹„(êµí†µë¹„) ì‹ ì²­_2003708.html\n",
      "ì²˜ë¦¬ ì¤‘... [900/6587] 20120118_[ê²°ì œí’ˆì˜]1ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-IPRì‚¬ì—…íŒ€_2003805.html\n",
      "ì²˜ë¦¬ ì¤‘... [1000/6587] 20120217_ê¹€í•˜ì‘ì°¨ì¥ í‡´ì§ê±´_2003907.html\n",
      "ì²˜ë¦¬ ì¤‘... [1100/6587] 20120322_ì—°ì°¨íœ´ê°€ ì‚¬ìš©ì‹ ì²­(4_27, 4_30)_2004008.html\n",
      "ì²˜ë¦¬ ì¤‘... [1200/6587] 20120424_4ì›”25ì¼ ì˜ˆë¹„êµ°í›ˆë ¨ì…ë‹ˆë‹¤_2004107.html\n",
      "ì²˜ë¦¬ ì¤‘... [1300/6587] 20120525_[ì±„ìš©í’ˆì˜]ê²½ë ¥ì‚¬ì› ì…ì‚¬ í’ˆì˜-ì˜¤ê²½ì§„_2004202.html\n",
      "ì²˜ë¦¬ ì¤‘... [1400/6587] 20120626_ê¸°ì •ì› - 2012ë…„ 6ì›” CARD ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (5021-2314-9983-0904)_2004306.html\n",
      "ì²˜ë¦¬ ì¤‘... [1500/6587] 20120726_7ì›” ë²•ì¸ì¹´ë“œì‚¬ìš© ì •ì‚° í’ˆì˜_2004418.html\n",
      "ì²˜ë¦¬ ì¤‘... [1600/6587] 20120817_ë¶€ë™ì‚° ì†Œìœ ê¶Œì´ì „ ë“±ê¸°ë¹„ìš© ì§€ê¸‰í’ˆì˜_2004505.html\n",
      "ì²˜ë¦¬ ì¤‘... [1700/6587] 20120913_[ê²°ì œí’ˆì˜]9ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜(9_17 ê²°ì œê±´)-IPRì‚¬ì—…ë¶€_2004609.html\n",
      "ì²˜ë¦¬ ì¤‘... [1800/6587] 20121004_ì—°ì°¨íœ´ê°€í’ˆì˜_2004704.html\n",
      "ì²˜ë¦¬ ì¤‘... [1900/6587] 20121030_[ê²°ì œí’ˆì˜]ë…¸íŠ¸ë¶ êµ¬ë§¤-ì±„ê°‘ë³‘ìƒë¬´_2004811.html\n",
      "ì²˜ë¦¬ ì¤‘... [2000/6587] 20121123_[ì±„ìš©í’ˆì˜]ê²½ë ¥ì‚¬ì› ì…ì‚¬ í’ˆì˜-ì´ì†¡ì—°_2004910.html\n",
      "ì²˜ë¦¬ ì¤‘... [2100/6587] 20121227_2012ë…„12ì›” ë²•ì¸ì¹´ë“œ ì‚¬ìš© ë‚´ì—­ ì •ì‚° ë³´ê³ _2005014.html\n",
      "ì²˜ë¦¬ ì¤‘... [2200/6587] 20130123_[ê²°ì œí’ˆì˜]ê·¹ì§€ì—°êµ¬ì†Œ ì‹ ê²½ì˜ì‹œìŠ¤í…œ êµ¬ì¶•( Web_Was ë¶€ë¬¸-í‹°ë§¥ìŠ¤ì†Œí”„íŠ¸) ì¤‘ë„ê¸ˆ ì§€ê¸‰ì˜ ê±´_2005106.html\n",
      "ì²˜ë¦¬ ì¤‘... [2300/6587] 20130218_2013ë…„01ì›” ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚°ë³´ê³ _2005211.html\n",
      "ì²˜ë¦¬ ì¤‘... [2400/6587] 20130314_ì˜ˆë¹„êµ°í›ˆë ¨_2005307.html\n",
      "ì²˜ë¦¬ ì¤‘... [2500/6587] 20130415_ì„ì› ì—°ì„ ë“±ê¸°ë¹„ìš© ì§€ê¸‰í’ˆì˜_2005405.html\n",
      "ì²˜ë¦¬ ì¤‘... [2600/6587] 20130509_5ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜(5 _15 ì§€ê¸‰ê±´)-SWì‚¬ì—…ë³¸ë¶€_2005509.html\n",
      "ì²˜ë¦¬ ì¤‘... [2700/6587] 20130529_[ITOê³„ì•½í’ˆì˜] LGí™”í•™ ê¸°ìˆ ì—°êµ¬ì› íŠ¹í—ˆì‹œìŠ¤í…œ ê°œì„ í”„ë¡œì íŠ¸ (ê¹€ì¢…ëª…)_2005608.html\n",
      "ì²˜ë¦¬ ì¤‘... [2800/6587] 20130620_í•˜ê³„ íœ´ê°€ í’ˆì˜_2005701.html\n",
      "ì²˜ë¦¬ ì¤‘... [2900/6587] 20130711_ê¸°ì •ì› íŠ¹ì„±í™”ê³ ì§€ì›ì‚¬ì—…ê´€ë¦¬ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ S_W êµ¬ë§¤ í’ˆì˜ ê±´ (DB ì•”í˜¸í™”ì†”ë£¨ì…˜)_2005807.html\n",
      "ì²˜ë¦¬ ì¤‘... [3000/6587] 20130729_LGë””ìŠ¤í”Œë ˆì´ ì¶œì¥ë¹„ í’ˆì˜_2005917.html\n",
      "ì²˜ë¦¬ ì¤‘... [3100/6587] 20130820_[ê²°ì œí’ˆì˜]ìƒí‘œì¶œì›ìˆ˜ìˆ˜ë£Œ_2006007.html\n",
      "ì²˜ë¦¬ ì¤‘... [3200/6587] 20130905_ì¶œì¥ êµí†µë¹„ í’ˆì˜_2006106.html\n",
      "ì²˜ë¦¬ ì¤‘... [3300/6587] 20131001_ì—°ì°¨ ìƒì‹  ë“œë¦½ë‹ˆë‹¤._2006205.html\n",
      "ì²˜ë¦¬ ì¤‘... [3400/6587] 20131024_ìê²©ì¦ ì‘ì‹œë¹„ìš© ì§€ê¸‰ ìš”ì²­ ë“œë¦½ë‹ˆë‹¤._2006305.html\n",
      "ì²˜ë¦¬ ì¤‘... [3500/6587] 20131112_ETRI í”„ë¡œì íŠ¸ ì¥ê¸° ì¶œì¥ í’ˆì˜ì˜ ê±´_2006406.html\n",
      "ì²˜ë¦¬ ì¤‘... [3600/6587] 20131129_ëŒ€ì „ ì¶œì¥ë¹„ í’ˆì˜_2006508.html\n",
      "ì²˜ë¦¬ ì¤‘... [3700/6587] 20131230_ETRI í”„ë¡œì íŠ¸ ìˆ™ì†Œ ì—°ì¥ ê³„ì•½ì˜ ê±´_2006610.html\n",
      "ì²˜ë¦¬ ì¤‘... [3800/6587] 20140123_2014ë…„ 1ì›” ê¸‰ì—¬ì§€ê¸‰ í’ˆì˜_2006710.html\n",
      "ì²˜ë¦¬ ì¤‘... [3900/6587] 20140215_ì—°ì°¨íœ´ê°€ í’ˆì˜_2006807.html\n",
      "ì²˜ë¦¬ ì¤‘... [4000/6587] 20140310_ê³µê°€ì‚¬ìš© í’ˆì˜( ë¯¼ë°©ìœ„ í›ˆë ¨ )_2006907.html\n",
      "ì²˜ë¦¬ ì¤‘... [4100/6587] 20140403_ëŒ€ì „ ìˆ™ì†Œ ê²½ë¹„ ì‹ ì²­(201402)_2007011.html\n",
      "ì²˜ë¦¬ ì¤‘... [4200/6587] 20140428_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ _2014ë…„04ì›”_ì´í˜•ê· _2007103.html\n",
      "ì²˜ë¦¬ ì¤‘... [4300/6587] 20140522_í•™ìê¸ˆ ì§€ê¸‰ ì‹ ì²­_2007198.html\n",
      "ì²˜ë¦¬ ì¤‘... [4400/6587] 20140612_6ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜(6_16ì§€ê¸‰ê±´)-ëŒ€ì „ì§€ì‚¬_2007306.html\n",
      "ì²˜ë¦¬ ì¤‘... [4500/6587] 20140703_ì‚¬ê¸°ì§„ì‘ë¹„ ì§€ê¸‰ ì‹ ì²­(20140703)_2007407.html\n",
      "ì²˜ë¦¬ ì¤‘... [4600/6587] 20140727_ì‚¼ì„±í† íƒˆ ìˆ™ì†Œ ê²½ë¹„ ì‹ ì²­(7ì›”)_2007508.html\n",
      "ì²˜ë¦¬ ì¤‘... [4700/6587] 20140811_í•˜ê³„íœ´ê°€ í’ˆì˜_2007601.html\n",
      "ì²˜ë¦¬ ì¤‘... [4800/6587] 20140910_ë°˜ì°¨ íœ´ê°€ë¥¼ ì‹ ì²­í•©ë‹ˆë‹¤ _2007709.html\n",
      "ì²˜ë¦¬ ì¤‘... [4900/6587] 20141006_ì¬ì§ì¦ëª…ì„œ ìš”ì²­ë“œë¦½ë‹ˆë‹¤._2007805.html\n",
      "ì²˜ë¦¬ ì¤‘... [5000/6587] 20141106_10ì›” ê°œì¸ê²½ë¹„ ì‹ ì²­_2007910.html\n",
      "ì²˜ë¦¬ ì¤‘... [5100/6587] 20141203_11ì›” ë²•ì¸ì¹´ë“œì‚¬ìš©ë‚´ì—­ í’ˆì˜_2008008.html\n",
      "ì²˜ë¦¬ ì¤‘... [5200/6587] 20141229_ì—°ì°¨íœ´ê°€ í’ˆì˜_2008097.html\n",
      "ì²˜ë¦¬ ì¤‘... [5300/6587] 20150127_2015ë…„ 01ì›” ì²´í¬ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ì„œ_2008216.html\n",
      "ì²˜ë¦¬ ì¤‘... [5400/6587] 20150224_ì—°ì°¨íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤_2008310.html\n",
      "ì²˜ë¦¬ ì¤‘... [5500/6587] 20150319_ì‹œë‚´êµí†µë¹„ í’ˆì˜_2008406.html\n",
      "ì²˜ë¦¬ ì¤‘... [5600/6587] 20150414_êµí†µë¹„ í’ˆì˜_2008508.html\n",
      "ì²˜ë¦¬ ì¤‘... [5700/6587] 20150512_[ëŒ€ê¸ˆê²°ì œ]IITP ICTê¸°ìˆ ì‚¬ì—…í™” ì •ë³´ì‹œìŠ¤í…œêµ¬ì¶•(1ë‹¨ê³„)_ì›¹ì·¨ì•½ì„± ì ê²€ _2008610.html\n",
      "ì²˜ë¦¬ ì¤‘... [5800/6587] 20150607_ì¥ê¸° ì¶œì¥ë¹„ í’ˆì˜(ëŒ€ì „)_2008707.html\n",
      "ì²˜ë¦¬ ì¤‘... [5900/6587] 20150701_LGí™”í•™ê¸°ìˆ ì› ì œì•ˆì‘ì—…ì„ ìœ„í•œ ì¶œì¥ í’ˆì˜_2008812.html\n",
      "ì²˜ë¦¬ ì¤‘... [6000/6587] 20150728_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³  - í˜„ê´‘ì„­(2015.07)_2008909.html\n",
      "ì²˜ë¦¬ ì¤‘... [6100/6587] 20150825_2015ë…„ 08ì›” ë²•ì¸ì¹´ë“œ ì •ì‚° í’ˆì˜(ë°•ìƒíƒ)_2009008.html\n",
      "ì²˜ë¦¬ ì¤‘... [6200/6587] 20150923_ì¥ê¸°ì¶œì¥ í’ˆì˜_2009107.html\n",
      "ì²˜ë¦¬ ì¤‘... [6300/6587] 20151020_ì¡ì½”ë¦¬ì•„ ì¸ì¬ì„œì¹­ ì„œë¹„ìŠ¤ 100ê±´(150ì¼ì‚¬ìš©) ì‹ ì²­_2009206.html\n",
      "ì²˜ë¦¬ ì¤‘... [6400/6587] 20151118_ì—°ì°¨ íœ´ê°€ í’ˆì˜_2009309.html\n",
      "ì²˜ë¦¬ ì¤‘... [6500/6587] 20151214_ì—°ì°¨íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤._2009409.html\n",
      "ì²˜ë¦¬ ì¤‘... [6587/6587] 20151231_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³  - í˜„ê´‘ì„­(2015.12)_2009496.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (6587ê±´) ===\n",
      "  ì§„í–‰: 100/6587 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/6587 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/6587 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/6587 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/6587 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/6587 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/6587 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/6587 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 900/6587 (ë§¤ì¹­: 900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1000/6587 (ë§¤ì¹­: 1000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1100/6587 (ë§¤ì¹­: 1100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1200/6587 (ë§¤ì¹­: 1200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1300/6587 (ë§¤ì¹­: 1300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1400/6587 (ë§¤ì¹­: 1400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1500/6587 (ë§¤ì¹­: 1500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1600/6587 (ë§¤ì¹­: 1600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1700/6587 (ë§¤ì¹­: 1700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1800/6587 (ë§¤ì¹­: 1800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1900/6587 (ë§¤ì¹­: 1900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2000/6587 (ë§¤ì¹­: 2000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2100/6587 (ë§¤ì¹­: 2100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2200/6587 (ë§¤ì¹­: 2200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2300/6587 (ë§¤ì¹­: 2300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2400/6587 (ë§¤ì¹­: 2400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2500/6587 (ë§¤ì¹­: 2500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2600/6587 (ë§¤ì¹­: 2600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2700/6587 (ë§¤ì¹­: 2700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2800/6587 (ë§¤ì¹­: 2800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2900/6587 (ë§¤ì¹­: 2900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3000/6587 (ë§¤ì¹­: 3000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3100/6587 (ë§¤ì¹­: 3100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3200/6587 (ë§¤ì¹­: 3200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3300/6587 (ë§¤ì¹­: 3300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3400/6587 (ë§¤ì¹­: 3400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3500/6587 (ë§¤ì¹­: 3500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3600/6587 (ë§¤ì¹­: 3600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3700/6587 (ë§¤ì¹­: 3700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3800/6587 (ë§¤ì¹­: 3800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3900/6587 (ë§¤ì¹­: 3900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4000/6587 (ë§¤ì¹­: 4000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4100/6587 (ë§¤ì¹­: 4100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4200/6587 (ë§¤ì¹­: 4200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4300/6587 (ë§¤ì¹­: 4300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4400/6587 (ë§¤ì¹­: 4400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4500/6587 (ë§¤ì¹­: 4500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4600/6587 (ë§¤ì¹­: 4600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4700/6587 (ë§¤ì¹­: 4700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4800/6587 (ë§¤ì¹­: 4800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4900/6587 (ë§¤ì¹­: 4900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5000/6587 (ë§¤ì¹­: 5000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5100/6587 (ë§¤ì¹­: 5100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5200/6587 (ë§¤ì¹­: 5200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5300/6587 (ë§¤ì¹­: 5300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5400/6587 (ë§¤ì¹­: 5400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5500/6587 (ë§¤ì¹­: 5500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5600/6587 (ë§¤ì¹­: 5600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5700/6587 (ë§¤ì¹­: 5700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5800/6587 (ë§¤ì¹­: 5800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5900/6587 (ë§¤ì¹­: 5900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6000/6587 (ë§¤ì¹­: 6000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6100/6587 (ë§¤ì¹­: 6100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6200/6587 (ë§¤ì¹­: 6200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6300/6587 (ë§¤ì¹­: 6300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6400/6587 (ë§¤ì¹­: 6400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6500/6587 (ë§¤ì¹­: 6500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6587/6587 (ë§¤ì¹­: 6587, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 6587ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 6587ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "#actionComment  ì¶”ì¶œ ê°œì„ \n",
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\"\"\"\n",
    " [ê¸°ëŠ¥]\n",
    " HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë¥¼ ì¬ì¶”ì¶œí•˜ì—¬\n",
    " DB documents í…Œì´ë¸”ì˜ í•´ë‹¹ ì»¬ëŸ¼ë§Œ UPDATE\n",
    " (í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€)\n",
    "\n",
    " [ì¶”ì¶œ ëŒ€ìƒ]\n",
    " - drafter: ê¸°ì•ˆì ì •ë³´ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì\" í–‰ì—ì„œ)\n",
    " - createdAt: ê¸°ì•ˆì¼ì‹œ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì¼\" í–‰ì—ì„œ, KSTâ†’Unix ms)\n",
    " - activities: ê²°ì¬ í™œë™ ë¡œê·¸ (bg02 divì—ì„œ)\n",
    "   - actionComment: user_spansì—ì„œ ì¶”ê°€ ì¶”ì¶œ\n",
    "\n",
    " [CSV ì¡°ì§ë„ ë§¤ì¹­]\n",
    " - í˜„ì§ì: CSVì—ì„œ positionName, deptName, emailId, deptCode ë§¤ì¹­\n",
    " - í‡´ì‚¬ì: emailIdë¥¼ 'master'ë¡œ ì„¤ì •, ë‚˜ë¨¸ì§€ ê³µë€\n",
    "\n",
    " [activities ì¶”ì¶œ ë¡œì§]\n",
    " 1. bg02 div ë‚´ ul > liì—ì„œ ì´ë¦„, íƒ€ì…, ë‚ ì§œ ì¶”ì¶œ\n",
    " 2. íƒ€ì… ê²°ì •: ê¸°ì•ˆâ†’DRAFT, í•©ì˜â†’AGREEMENT, ê·¸ì™¸â†’APPROVAL\n",
    " 3. ë‚ ì§œ: MM/DD í˜•ì‹ â†’ createdAt ì—°ë„ + KST ë³€í™˜\n",
    " 4. actionComment: user_spans ìˆœíšŒí•˜ë©° ë‹¤ìŒ divì—ì„œ ì˜ê²¬ ì¶”ì¶œ\n",
    "\n",
    " [ì‹œê°„ëŒ€ ì²˜ë¦¬]\n",
    " - ëª¨ë“  ë‚ ì§œë¥¼ KST(Asia/Seoul)ë¡œ ì²˜ë¦¬ í›„ Unix timestamp ë³€í™˜\n",
    "\n",
    " [ë™ì‘ ìˆœì„œ]\n",
    " 1. CSV ì¡°ì§ë„ ë¡œë“œ\n",
    " 2. HTML í´ë”ì—ì„œ íŒŒì¼ ìˆœíšŒ\n",
    " 3. ê° HTMLì—ì„œ drafter, createdAt, activities ì¶”ì¶œ\n",
    " 4. JSON íŒŒì¼ë¡œ ì €ì¥\n",
    " 5. DB UPDATE (source_id + end_yearë¡œ ë§¤ì¹­)\n",
    "\n",
    " [ì¶œë ¥]\n",
    " - JSON íŒŒì¼: update_drafter_activities.json\n",
    " - MariaDB: documents í…Œì´ë¸”ì˜ drafter_*, created_at, activities ì»¬ëŸ¼ UPDATE\n",
    "\n",
    " [ì„¤ì • (#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)]\n",
    " - base_path: HTML í´ë” ê²½ë¡œ\n",
    " - end_year: ëŒ€ìƒ ì—°ë„ (WHERE ì¡°ê±´)\n",
    " - csv_file: ì¸ì‚¬ì •ë³´ CSV íŒŒì¼\n",
    " - db_config: DB ì ‘ì† ì •ë³´\n",
    "\n",
    " [ì˜ì¡´ì„±]\n",
    " - beautifulsoup4\n",
    " - pymysql\n",
    " - pandas\n",
    " - pytz\n",
    " -> pip install beautifulsoup4 pymysql pandas pytz\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) - ê°œì„ ë¨ ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_span ì´í›„ ë‹¤ìŒ user_span ì „ê¹Œì§€ì˜ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    \n",
    "                    # next_siblingsë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ íƒìƒ‰\n",
    "                    for sibling in user_span.next_siblings:\n",
    "                        # ë‹¤ìŒ user_spanì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨\n",
    "                        if hasattr(sibling, 'name'):\n",
    "                            if sibling.name == 'span' and 'user' in sibling.get('class', []):\n",
    "                                break\n",
    "                            # divë¥¼ ì°¾ìœ¼ë©´ ì €ì¥í•˜ê³  ì¤‘ë‹¨\n",
    "                            if sibling.name == 'div':\n",
    "                                action_comment = sibling.get_text(strip=True)\n",
    "                                break\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html'\n",
    "    end_year = 2015\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b6a8c8-db98-4d35-bffd-1c5ebacde3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 840ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/840] 20100225_ì—°ì°¨íœ´ê°€(3_2) ì‹ ì²­í•©ë‹ˆë‹¤._2002163.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/840] 20100401_[ê¸°ìˆ ì§€ì›íŒ€ ê²©ë ¤ ì¸ì„¼í‹°ë¸Œ ì§€ê¸‰í’ˆì˜]_2002268.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/840] 20100517_ê°œì¸íœ´ê°€í’ˆì˜_2002367.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/840] 20100705_íŒŒì¼ì„œë²„ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­_2002467.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/840] 20100817_8ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ê¸°ìˆ ì§€ì›ë¶€ë¬¸_2002570.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/840] 20100929_ì¬ì§ì¦ëª…ì„œ ë°œê¸‰ìš”ì²­_2002666.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/840] 20101110_ëŒ€ì „ì§€ì‚¬ ê³µìš© í•˜ë“œë””ìŠ¤í¬ êµ¬ë§¤ ìš”ì²­_2002767.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/840] 20101221_12ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ì „ë¬¸ê°€Gr.(ê¹€ê·œì¼)_2002865.html\n",
      "ì²˜ë¦¬ ì¤‘... [840/840] 20101231_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (10ì›”,11ì›”,12ì›”)_2002907.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (840ê±´) ===\n",
      "  ì§„í–‰: 100/840 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/840 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/840 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/840 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/840 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/840 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/840 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/840 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 840/840 (ë§¤ì¹­: 840, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 840ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 840ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz  # â† ì¶”ê°€\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')  # â† ì¶”ê°€: í•œêµ­ ì‹œê°„ëŒ€\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        # naive datetime ìƒì„± í›„ KSTë¡œ ëª…ì‹œ\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬ ì¶”ê°€\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_spanì˜ ë¶€ëª¨(td)ì—ì„œ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    parent = user_span.parent\n",
    "                    if parent:\n",
    "                        comment_div = parent.find('div')\n",
    "                        if comment_div:\n",
    "                            action_comment = comment_div.get_text(strip=True)\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS  # â† ì¶”ê°€!\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜ (ë³€ê²½ ì—¬ë¶€ ë¬´ê´€)\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html'\n",
    "    end_year = 2015\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
