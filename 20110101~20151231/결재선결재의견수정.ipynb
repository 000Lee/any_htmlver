{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9cd056-97ee-4ca0-829b-63e9a0e6683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CSV Ï°∞ÏßÅÎèÑ Î°úÎìú Ï§ë... (Ïù∏ÏÇ¨Ï†ïÎ≥¥_Î∂ÄÏÑúÏΩîÎìúÏ∂îÍ∞Ä.csv)\n",
      "‚úÖ Ï¥ù 156Î™Ö Î°úÎìú\n",
      "\n",
      "HTML ÌååÏùº ÌååÏã± ÏãúÏûë...\n",
      "Ï¥ù 6587Í∞úÏùò HTML ÌååÏùºÏùÑ Ï∞æÏïòÏäµÎãàÎã§.\n",
      "Ï≤òÎ¶¨ Ï§ë... [100/6587] 20110217_LGÏ†ÑÏûê G-TIPIS Î∂ÅÍ≤Ω Ï∂úÏû•ÎπÑ Ïã†Ï≤≠_2003007.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [200/6587] 20110329_2011ÎÖÑ 3Ïõî CARD ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥†_Ïù¥ÌòïÍ∑†_2003110.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [300/6587] 20110506_ÏïàÎÖïÌïòÏÑ∏Ïöî Ïï†ÎãàÌååÏù¥Î∏åÏãúÏä§ÌÖúÏùò ÍπÄÌòÑÏ§ë ÏûÖÎãàÎã§ ÏòàÎπÑÍµ∞ ÌõàÎ†®ÏúºÎ°ú Ïù∏Ìïú Ìú¥Í∞Ä Ïã†Ï≤≠Ìï©ÎãàÎã§_2003207.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [400/6587] 20110624_Ïó∞Ï∞® Ìú¥Í∞Ä ÌíàÏùò_2003305.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [500/6587] 20110801_ÏÇºÏÑ±ÏΩîÎãù Ï∂úÏû•ÏãùÎåÄ(Ï°∞_ÏÑùÏãù) Ïã†Ï≤≠(7_18~7_29)_2003407.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [600/6587] 20110926_[Íµ¨Îß§ÌíàÏùò]ÎÖ∏Ìä∏Î∂Å Íµ¨Îß§-Ïã†ÏûÖÏÇ¨Ïõê(ÍπÄÌôòÏö©, Î∞ïÏÉÅÏïà, ÍπÄÎ¥âÎØº)_2003506.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [700/6587] 20111101_ÌïúÍµ≠ÌïúÏùòÌïôÏó∞Íµ¨Ïõê - 2011ÎÖÑ 10Ïõî CARD ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥†(5021-2314-9982-6902)_2003607.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [800/6587] 20111206_Íµ≠ÎÇ¥Ï∂úÏû•ÎπÑ(ÍµêÌÜµÎπÑ) Ïã†Ï≤≠_2003708.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [900/6587] 20120118_[Í≤∞Ï†úÌíàÏùò]1Ïõî ÏïÑÏõÉÏÜåÏã± Ïù∏Í±¥ÎπÑ ÏßÄÍ∏â ÌíàÏùò-IPRÏÇ¨ÏóÖÌåÄ_2003805.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1000/6587] 20120217_ÍπÄÌïòÏùëÏ∞®Ïû• Ìá¥ÏßÅÍ±¥_2003907.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1100/6587] 20120322_Ïó∞Ï∞®Ìú¥Í∞Ä ÏÇ¨Ïö©Ïã†Ï≤≠(4_27, 4_30)_2004008.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1200/6587] 20120424_4Ïõî25Ïùº ÏòàÎπÑÍµ∞ÌõàÎ†®ÏûÖÎãàÎã§_2004107.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1300/6587] 20120525_[Ï±ÑÏö©ÌíàÏùò]Í≤ΩÎ†•ÏÇ¨Ïõê ÏûÖÏÇ¨ ÌíàÏùò-Ïò§Í≤ΩÏßÑ_2004202.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1400/6587] 20120626_Í∏∞Ï†ïÏõê - 2012ÎÖÑ 6Ïõî CARD ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥†(5021-2314-9983-0904)_2004306.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1500/6587] 20120726_7Ïõî Î≤ïÏù∏Ïπ¥ÎìúÏÇ¨Ïö© Ï†ïÏÇ∞ ÌíàÏùò_2004418.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1600/6587] 20120817_Î∂ÄÎèôÏÇ∞ ÏÜåÏú†Í∂åÏù¥Ï†Ñ Îì±Í∏∞ÎπÑÏö© ÏßÄÍ∏âÌíàÏùò_2004505.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1700/6587] 20120913_[Í≤∞Ï†úÌíàÏùò]9Ïõî ÏïÑÏõÉÏÜåÏã± Ïù∏Í±¥ÎπÑ ÏßÄÍ∏â ÌíàÏùò(9_17 Í≤∞Ï†úÍ±¥)-IPRÏÇ¨ÏóÖÎ∂Ä_2004609.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1800/6587] 20121004_Ïó∞Ï∞®Ìú¥Í∞ÄÌíàÏùò_2004704.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [1900/6587] 20121030_[Í≤∞Ï†úÌíàÏùò]ÎÖ∏Ìä∏Î∂Å Íµ¨Îß§-Ï±ÑÍ∞ëÎ≥ëÏÉÅÎ¨¥_2004811.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2000/6587] 20121123_[Ï±ÑÏö©ÌíàÏùò]Í≤ΩÎ†•ÏÇ¨Ïõê ÏûÖÏÇ¨ ÌíàÏùò-Ïù¥ÏÜ°Ïó∞_2004910.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2100/6587] 20121227_2012ÎÖÑ12Ïõî Î≤ïÏù∏Ïπ¥Îìú ÏÇ¨Ïö© ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥†_2005014.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2200/6587] 20130123_[Í≤∞Ï†úÌíàÏùò]Í∑πÏßÄÏó∞Íµ¨ÏÜå Ïã†Í≤ΩÏòÅÏãúÏä§ÌÖú Íµ¨Ï∂ï( Web_Was Î∂ÄÎ¨∏-Ìã∞Îß•Ïä§ÏÜåÌîÑÌä∏) Ï§ëÎèÑÍ∏à ÏßÄÍ∏âÏùò Í±¥_2005106.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2300/6587] 20130218_2013ÎÖÑ01Ïõî Î≤ïÏù∏Ïπ¥Îìú ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞Î≥¥Í≥†_2005211.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2400/6587] 20130314_ÏòàÎπÑÍµ∞ÌõàÎ†®_2005307.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2500/6587] 20130415_ÏûÑÏõê Ïó∞ÏûÑ Îì±Í∏∞ÎπÑÏö© ÏßÄÍ∏âÌíàÏùò_2005405.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2600/6587] 20130509_5Ïõî ÏïÑÏõÉÏÜåÏã± Ïù∏Í±¥ÎπÑ ÏßÄÍ∏â ÌíàÏùò(5 _15 ÏßÄÍ∏âÍ±¥)-SWÏÇ¨ÏóÖÎ≥∏Î∂Ä_2005509.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2700/6587] 20130529_[ITOÍ≥ÑÏïΩÌíàÏùò] LGÌôîÌïô Í∏∞Ïà†Ïó∞Íµ¨Ïõê ÌäπÌóàÏãúÏä§ÌÖú Í∞úÏÑ†ÌîÑÎ°úÏ†ùÌä∏ (ÍπÄÏ¢ÖÎ™Ö)_2005608.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2800/6587] 20130620_ÌïòÍ≥Ñ Ìú¥Í∞Ä ÌíàÏùò_2005701.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [2900/6587] 20130711_Í∏∞Ï†ïÏõê ÌäπÏÑ±ÌôîÍ≥†ÏßÄÏõêÏÇ¨ÏóÖÍ¥ÄÎ¶¨ÏãúÏä§ÌÖú Íµ¨Ï∂ïÏùÑ ÏúÑÌïú S_W Íµ¨Îß§ ÌíàÏùò Í±¥ (DB ÏïîÌò∏ÌôîÏÜîÎ£®ÏÖò)_2005807.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3000/6587] 20130729_LGÎîîÏä§ÌîåÎ†àÏù¥ Ï∂úÏû•ÎπÑ ÌíàÏùò_2005917.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3100/6587] 20130820_[Í≤∞Ï†úÌíàÏùò]ÏÉÅÌëúÏ∂úÏõêÏàòÏàòÎ£å_2006007.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3200/6587] 20130905_Ï∂úÏû• ÍµêÌÜµÎπÑ ÌíàÏùò_2006106.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3300/6587] 20131001_Ïó∞Ï∞® ÏÉÅÏã† ÎìúÎ¶ΩÎãàÎã§._2006205.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3400/6587] 20131024_ÏûêÍ≤©Ï¶ù ÏùëÏãúÎπÑÏö© ÏßÄÍ∏â ÏöîÏ≤≠ ÎìúÎ¶ΩÎãàÎã§._2006305.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3500/6587] 20131112_ETRI ÌîÑÎ°úÏ†ùÌä∏ Ïû•Í∏∞ Ï∂úÏû• ÌíàÏùòÏùò Í±¥_2006406.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3600/6587] 20131129_ÎåÄÏ†Ñ Ï∂úÏû•ÎπÑ ÌíàÏùò_2006508.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3700/6587] 20131230_ETRI ÌîÑÎ°úÏ†ùÌä∏ ÏàôÏÜå Ïó∞Ïû• Í≥ÑÏïΩÏùò Í±¥_2006610.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3800/6587] 20140123_2014ÎÖÑ 1Ïõî Í∏âÏó¨ÏßÄÍ∏â ÌíàÏùò_2006710.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [3900/6587] 20140215_Ïó∞Ï∞®Ìú¥Í∞Ä ÌíàÏùò_2006807.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4000/6587] 20140310_Í≥µÍ∞ÄÏÇ¨Ïö© ÌíàÏùò( ÎØºÎ∞©ÏúÑ ÌõàÎ†® )_2006907.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4100/6587] 20140403_ÎåÄÏ†Ñ ÏàôÏÜå Í≤ΩÎπÑ Ïã†Ï≤≠(201402)_2007011.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4200/6587] 20140428_Î≤ïÏù∏Ïπ¥Îìú ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥†_2014ÎÖÑ04Ïõî_Ïù¥ÌòïÍ∑†_2007103.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4300/6587] 20140522_ÌïôÏûêÍ∏à ÏßÄÍ∏â Ïã†Ï≤≠_2007198.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4400/6587] 20140612_6Ïõî ÏïÑÏõÉÏÜåÏã± Ïù∏Í±¥ÎπÑ ÏßÄÍ∏â ÌíàÏùò(6_16ÏßÄÍ∏âÍ±¥)-ÎåÄÏ†ÑÏßÄÏÇ¨_2007306.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4500/6587] 20140703_ÏÇ¨Í∏∞ÏßÑÏûëÎπÑ ÏßÄÍ∏â Ïã†Ï≤≠(20140703)_2007407.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4600/6587] 20140727_ÏÇºÏÑ±ÌÜ†ÌÉà ÏàôÏÜå Í≤ΩÎπÑ Ïã†Ï≤≠(7Ïõî)_2007508.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4700/6587] 20140811_ÌïòÍ≥ÑÌú¥Í∞Ä ÌíàÏùò_2007601.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4800/6587] 20140910_Î∞òÏ∞® Ìú¥Í∞ÄÎ•º Ïã†Ï≤≠Ìï©ÎãàÎã§ _2007709.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [4900/6587] 20141006_Ïû¨ÏßÅÏ¶ùÎ™ÖÏÑú ÏöîÏ≤≠ÎìúÎ¶ΩÎãàÎã§._2007805.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5000/6587] 20141106_10Ïõî Í∞úÏù∏Í≤ΩÎπÑ Ïã†Ï≤≠_2007910.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5100/6587] 20141203_11Ïõî Î≤ïÏù∏Ïπ¥ÎìúÏÇ¨Ïö©ÎÇ¥Ïó≠ ÌíàÏùò_2008008.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5200/6587] 20141229_Ïó∞Ï∞®Ìú¥Í∞Ä ÌíàÏùò_2008097.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5300/6587] 20150127_2015ÎÖÑ 01Ïõî Ï≤¥ÌÅ¨Ïπ¥Îìú ÏÇ¨Ïö©ÎÇ¥Ïó≠ÏÑú_2008216.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5400/6587] 20150224_Ïó∞Ï∞®Ìú¥Í∞Ä Ïã†Ï≤≠Ìï©ÎãàÎã§_2008310.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5500/6587] 20150319_ÏãúÎÇ¥ÍµêÌÜµÎπÑ ÌíàÏùò_2008406.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5600/6587] 20150414_ÍµêÌÜµÎπÑ ÌíàÏùò_2008508.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5700/6587] 20150512_[ÎåÄÍ∏àÍ≤∞Ï†ú]IITP ICTÍ∏∞Ïà†ÏÇ¨ÏóÖÌôî Ï†ïÎ≥¥ÏãúÏä§ÌÖúÍµ¨Ï∂ï(1Îã®Í≥Ñ)_ÏõπÏ∑®ÏïΩÏÑ± Ï†êÍ≤Ä _2008610.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5800/6587] 20150607_Ïû•Í∏∞ Ï∂úÏû•ÎπÑ ÌíàÏùò(ÎåÄÏ†Ñ)_2008707.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [5900/6587] 20150701_LGÌôîÌïôÍ∏∞Ïà†Ïõê Ï†úÏïàÏûëÏóÖÏùÑ ÏúÑÌïú Ï∂úÏû• ÌíàÏùò_2008812.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6000/6587] 20150728_Î≤ïÏù∏Ïπ¥Îìú ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥† - ÌòÑÍ¥ëÏÑ≠(2015.07)_2008909.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6100/6587] 20150825_2015ÎÖÑ 08Ïõî Î≤ïÏù∏Ïπ¥Îìú Ï†ïÏÇ∞ ÌíàÏùò(Î∞ïÏÉÅÌÉù)_2009008.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6200/6587] 20150923_Ïû•Í∏∞Ï∂úÏû• ÌíàÏùò_2009107.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6300/6587] 20151020_Ïû°ÏΩîÎ¶¨ÏïÑ Ïù∏Ïû¨ÏÑúÏπ≠ ÏÑúÎπÑÏä§ 100Í±¥(150ÏùºÏÇ¨Ïö©) Ïã†Ï≤≠_2009206.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6400/6587] 20151118_Ïó∞Ï∞® Ìú¥Í∞Ä ÌíàÏùò_2009309.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6500/6587] 20151214_Ïó∞Ï∞®Ìú¥Í∞Ä Ïã†Ï≤≠Ìï©ÎãàÎã§._2009409.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [6587/6587] 20151231_Î≤ïÏù∏Ïπ¥Îìú ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥† - ÌòÑÍ¥ëÏÑ≠(2015.12)_2009496.html\n",
      "JSON ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB Ïó∞Í≤∞ ÏãúÏûë ===\n",
      "Host: localhost, Database: any_approval\n",
      "‚úì DB Ïó∞Í≤∞ ÏÑ±Í≥µ (FOUND_ROWS Î™®Îìú)\n",
      "\n",
      "=== Îç∞Ïù¥ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏ ÏãúÏûë (6587Í±¥) ===\n",
      "  ÏßÑÌñâ: 100/6587 (Îß§Ïπ≠: 100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 200/6587 (Îß§Ïπ≠: 200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 300/6587 (Îß§Ïπ≠: 300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 400/6587 (Îß§Ïπ≠: 400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 500/6587 (Îß§Ïπ≠: 500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 600/6587 (Îß§Ïπ≠: 600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 700/6587 (Îß§Ïπ≠: 700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 800/6587 (Îß§Ïπ≠: 800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 900/6587 (Îß§Ïπ≠: 900, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1000/6587 (Îß§Ïπ≠: 1000, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1100/6587 (Îß§Ïπ≠: 1100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1200/6587 (Îß§Ïπ≠: 1200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1300/6587 (Îß§Ïπ≠: 1300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1400/6587 (Îß§Ïπ≠: 1400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1500/6587 (Îß§Ïπ≠: 1500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1600/6587 (Îß§Ïπ≠: 1600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1700/6587 (Îß§Ïπ≠: 1700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1800/6587 (Îß§Ïπ≠: 1800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 1900/6587 (Îß§Ïπ≠: 1900, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2000/6587 (Îß§Ïπ≠: 2000, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2100/6587 (Îß§Ïπ≠: 2100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2200/6587 (Îß§Ïπ≠: 2200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2300/6587 (Îß§Ïπ≠: 2300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2400/6587 (Îß§Ïπ≠: 2400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2500/6587 (Îß§Ïπ≠: 2500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2600/6587 (Îß§Ïπ≠: 2600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2700/6587 (Îß§Ïπ≠: 2700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2800/6587 (Îß§Ïπ≠: 2800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 2900/6587 (Îß§Ïπ≠: 2900, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3000/6587 (Îß§Ïπ≠: 3000, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3100/6587 (Îß§Ïπ≠: 3100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3200/6587 (Îß§Ïπ≠: 3200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3300/6587 (Îß§Ïπ≠: 3300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3400/6587 (Îß§Ïπ≠: 3400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3500/6587 (Îß§Ïπ≠: 3500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3600/6587 (Îß§Ïπ≠: 3600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3700/6587 (Îß§Ïπ≠: 3700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3800/6587 (Îß§Ïπ≠: 3800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 3900/6587 (Îß§Ïπ≠: 3900, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4000/6587 (Îß§Ïπ≠: 4000, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4100/6587 (Îß§Ïπ≠: 4100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4200/6587 (Îß§Ïπ≠: 4200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4300/6587 (Îß§Ïπ≠: 4300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4400/6587 (Îß§Ïπ≠: 4400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4500/6587 (Îß§Ïπ≠: 4500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4600/6587 (Îß§Ïπ≠: 4600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4700/6587 (Îß§Ïπ≠: 4700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4800/6587 (Îß§Ïπ≠: 4800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 4900/6587 (Îß§Ïπ≠: 4900, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5000/6587 (Îß§Ïπ≠: 5000, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5100/6587 (Îß§Ïπ≠: 5100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5200/6587 (Îß§Ïπ≠: 5200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5300/6587 (Îß§Ïπ≠: 5300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5400/6587 (Îß§Ïπ≠: 5400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5500/6587 (Îß§Ïπ≠: 5500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5600/6587 (Îß§Ïπ≠: 5600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5700/6587 (Îß§Ïπ≠: 5700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5800/6587 (Îß§Ïπ≠: 5800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 5900/6587 (Îß§Ïπ≠: 5900, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6000/6587 (Îß§Ïπ≠: 6000, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6100/6587 (Îß§Ïπ≠: 6100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6200/6587 (Îß§Ïπ≠: 6200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6300/6587 (Îß§Ïπ≠: 6300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6400/6587 (Îß§Ïπ≠: 6400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6500/6587 (Îß§Ïπ≠: 6500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 6587/6587 (Îß§Ïπ≠: 6587, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "\n",
      "=== Ïª§Î∞ã ÏãúÏûë ===\n",
      "‚úì Ïª§Î∞ã ÏôÑÎ£å\n",
      "\n",
      "=== Í≤∞Í≥º ÏöîÏïΩ ===\n",
      "‚úì Îß§Ïπ≠ ÏÑ±Í≥µ: 6587Í±¥\n",
      "‚ö† DBÏóê ÏóÜÏùå: 0Í±¥\n",
      "‚úó Ïò§Î•ò: 0Í±¥\n",
      "\n",
      "‚úì DB Ïó∞Í≤∞ Ï¢ÖÎ£å\n",
      "==================================================\n",
      "\n",
      "ÏôÑÎ£å! Ï¥ù 6587Í±¥ Ï≤òÎ¶¨Îê®\n"
     ]
    }
   ],
   "source": [
    "#actionComment  Ï∂îÏ∂ú Í∞úÏÑ†\n",
    "# drafter, createdAt, activitiesÎßå UPDATEÌïòÎäî Î≤ÑÏ†Ñ\n",
    "# ÌÖåÏù¥Î∏î Í∏∞Î∞ò Ï∂îÏ∂ú + CSV Ï°∞ÏßÅÎèÑ Îß§Ïπ≠ + Í≤∞Ïû¨ÏùòÍ≤¨ Ï∂îÍ∞Ä + KST ÏãúÍ∞ÑÎåÄ Ï≤òÎ¶¨\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')\n",
    "        \n",
    "        # CSV Ï°∞ÏßÅÎèÑ Î°úÎìú\n",
    "        print(f\"üìä CSV Ï°∞ÏßÅÎèÑ Î°úÎìú Ï§ë... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ÏÇ¨ÏõêÎ™Ö']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['Î∂ÄÏÑú'],\n",
    "                'empNo': row['ÏÇ¨ÏõêÎ≤àÌò∏'] if pd.notna(row['ÏÇ¨ÏõêÎ≤àÌò∏']) else '',\n",
    "                'positionName': row['ÏßÅÏúÑ'] if pd.notna(row['ÏßÅÏúÑ']) else '',\n",
    "                'deptCode': row['Î∂ÄÏÑúÏΩîÎìú'] if pd.notna(row['Î∂ÄÏÑúÏΩîÎìú']) else ''\n",
    "            }\n",
    "        print(f\"‚úÖ Ï¥ù {len(self.employee_dict)}Î™Ö Î°úÎìú\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"ÌååÏùºÎ™ÖÏóêÏÑú ÎßàÏßÄÎßâ Ïà´Ïûê Ï∂îÏ∂ú\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"Ïù¥Î¶Ñ/ÏßÅÏ±Ö/Î∂ÄÏÑú ÌòïÏãùÏóêÏÑú Ï†ïÎ≥¥ Ï∂îÏ∂ú\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML ÌååÏùºÏóêÏÑú drafter, createdAt, activitiesÎßå Ï∂îÏ∂ú\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter Ï∂îÏ∂ú (ÌÖåÏù¥Î∏îÏóêÏÑú) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'Í∏∞ÏïàÏûê' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV Ï°∞ÏßÅÎèÑ Îß§Ïπ≠\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # Ìá¥ÏÇ¨Ïûê\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt Ï∂îÏ∂ú (ÌÖåÏù¥Î∏îÏóêÏÑú) - KST Ï≤òÎ¶¨ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'Í∏∞ÏïàÏùº' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities Ï∂îÏ∂ú (bg02ÏóêÏÑú) - KST Ï≤òÎ¶¨ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # ÌÉÄÏûÖ Í≤∞Ï†ï\n",
    "                        if 'Í∏∞Ïïà' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'Ìï©Ïùò' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ÎÇ†Ïßú Î≥ÄÌôò (00:00:00) - KST Ï≤òÎ¶¨\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV Ï°∞ÏßÅÎèÑ Îß§Ïπ≠\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # Ìá¥ÏÇ¨Ïûê\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ÏùºÎã® ÎπàÍ∞í\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment Ï∂îÍ∞Ä (user_spansÏóêÏÑú) - Í∞úÏÑ†Îê® ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ÏùòÍ≤¨ Ï∂îÏ∂ú - user_span Ïù¥ÌõÑ Îã§Ïùå user_span Ï†ÑÍπåÏßÄÏùò div Ï∞æÍ∏∞\n",
    "                    action_comment = \"\"\n",
    "                    \n",
    "                    # next_siblingsÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÏàúÏ∞® ÌÉêÏÉâ\n",
    "                    for sibling in user_span.next_siblings:\n",
    "                        # Îã§Ïùå user_spanÏùÑ ÎßåÎÇòÎ©¥ Ï§ëÎã®\n",
    "                        if hasattr(sibling, 'name'):\n",
    "                            if sibling.name == 'span' and 'user' in sibling.get('class', []):\n",
    "                                break\n",
    "                            # divÎ•º Ï∞æÏúºÎ©¥ Ï†ÄÏû•ÌïòÍ≥† Ï§ëÎã®\n",
    "                            if sibling.name == 'div':\n",
    "                                action_comment = sibling.get_text(strip=True)\n",
    "                                break\n",
    "                    \n",
    "                    # activitiesÏóêÏÑú Ïù¥Î¶Ñ Ï∞æÏïÑÏÑú ÏùòÍ≤¨ Ï∂îÍ∞Ä\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # Í≤∞Í≥º Î∞òÌôò (ÌïÑÏöîÌïú 3Í∞ÄÏßÄÎßå)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"Î™®Îì† HTML ÌååÏùº Ï≤òÎ¶¨\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'Í≤∞Ïû¨'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"Í≤ΩÎ°úÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"Ï¥ù {len(html_files)}Í∞úÏùò HTML ÌååÏùºÏùÑ Ï∞æÏïòÏäµÎãàÎã§.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"Ï≤òÎ¶¨ Ï§ë... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Ïò§Î•ò Î∞úÏÉù ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON ÌååÏùºÎ°ú Ï†ÄÏû•\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB ÌäπÏ†ï Ïª¨ÎüºÎßå UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB Ïó∞Í≤∞ ÏãúÏûë ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB Ïó∞Í≤∞ - FOUND_ROWS ÌîåÎûòÍ∑∏ Ï∂îÍ∞Ä\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS\n",
    "            )\n",
    "            print(\"‚úì DB Ïó∞Í≤∞ ÏÑ±Í≥µ (FOUND_ROWS Î™®Îìú)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ÏøºÎ¶¨\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== Îç∞Ïù¥ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏ ÏãúÏûë ({len(data)}Í±¥) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS Î™®Îìú: Îß§Ïπ≠Îêú Ìñâ Ïàò Î∞òÌôò\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ÏßÑÌñâ: {idx}/{len(data)} (Îß§Ïπ≠: {success_count}, ÏóÜÏùå: {not_found_count}, Ïã§Ìå®: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [Ïò§Î•ò {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== Ïª§Î∞ã ÏãúÏûë ===\")\n",
    "            conn.commit()\n",
    "            print(\"‚úì Ïª§Î∞ã ÏôÑÎ£å\")\n",
    "            \n",
    "            print(f\"\\n=== Í≤∞Í≥º ÏöîÏïΩ ===\")\n",
    "            print(f\"‚úì Îß§Ïπ≠ ÏÑ±Í≥µ: {success_count}Í±¥\")\n",
    "            print(f\"‚ö† DBÏóê ÏóÜÏùå: {not_found_count}Í±¥\")\n",
    "            print(f\"‚úó Ïò§Î•ò: {error_count}Í±¥\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\n‚ö† DBÏóêÏÑú Î™ª Ï∞æÏùÄ source_id ÏÉòÌîå (Ï≤òÏùå 20Í∞ú):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nüìä DBÏùò source_id Î≤îÏúÑ: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nÏ≤òÏùå 5Í∞ú Ïô∏ {error_count - 5}Í∞úÏùò Ï∂îÍ∞Ä Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\")\n",
    "                print(\"Î™®Îì† Ïò§Î•ò Î≥¥Í∏∞:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... Ïô∏ {len(error_details) - 20}Í∞ú Îçî\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\n‚ùå DB Ïò§Î•ò Î∞úÏÉù:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå ÏùºÎ∞ò Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\n‚úì DB Ïó∞Í≤∞ Ï¢ÖÎ£å\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html'\n",
    "    end_year = 2015\n",
    "    csv_file = 'Ïù∏ÏÇ¨Ï†ïÎ≥¥_Î∂ÄÏÑúÏΩîÎìúÏ∂îÍ∞Ä.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML ÌååÏùº ÌååÏã± ÏãúÏûë...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nÏôÑÎ£å! Ï¥ù {len(results)}Í±¥ Ï≤òÎ¶¨Îê®\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b6a8c8-db98-4d35-bffd-1c5ebacde3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä CSV Ï°∞ÏßÅÎèÑ Î°úÎìú Ï§ë... (Ïù∏ÏÇ¨Ï†ïÎ≥¥_Î∂ÄÏÑúÏΩîÎìúÏ∂îÍ∞Ä.csv)\n",
      "‚úÖ Ï¥ù 156Î™Ö Î°úÎìú\n",
      "\n",
      "HTML ÌååÏùº ÌååÏã± ÏãúÏûë...\n",
      "Ï¥ù 840Í∞úÏùò HTML ÌååÏùºÏùÑ Ï∞æÏïòÏäµÎãàÎã§.\n",
      "Ï≤òÎ¶¨ Ï§ë... [100/840] 20100225_Ïó∞Ï∞®Ìú¥Í∞Ä(3_2) Ïã†Ï≤≠Ìï©ÎãàÎã§._2002163.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [200/840] 20100401_[Í∏∞Ïà†ÏßÄÏõêÌåÄ Í≤©Î†§ Ïù∏ÏÑºÌã∞Î∏å ÏßÄÍ∏âÌíàÏùò]_2002268.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [300/840] 20100517_Í∞úÏù∏Ìú¥Í∞ÄÌíàÏùò_2002367.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [400/840] 20100705_ÌååÏùºÏÑúÎ≤Ñ Ï†ëÍ∑º Í∂åÌïú ÏöîÏ≤≠_2002467.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [500/840] 20100817_8Ïõî ÏïÑÏõÉÏÜåÏã± Ïù∏Í±¥ÎπÑ ÏßÄÍ∏â ÌíàÏùò-Í∏∞Ïà†ÏßÄÏõêÎ∂ÄÎ¨∏_2002570.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [600/840] 20100929_Ïû¨ÏßÅÏ¶ùÎ™ÖÏÑú Î∞úÍ∏âÏöîÏ≤≠_2002666.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [700/840] 20101110_ÎåÄÏ†ÑÏßÄÏÇ¨ Í≥µÏö© ÌïòÎìúÎîîÏä§ÌÅ¨ Íµ¨Îß§ ÏöîÏ≤≠_2002767.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [800/840] 20101221_12Ïõî ÏïÑÏõÉÏÜåÏã± Ïù∏Í±¥ÎπÑ ÏßÄÍ∏â ÌíàÏùò-Ï†ÑÎ¨∏Í∞ÄGr.(ÍπÄÍ∑úÏùº)_2002865.html\n",
      "Ï≤òÎ¶¨ Ï§ë... [840/840] 20101231_Î≤ïÏù∏Ïπ¥Îìú ÏÇ¨Ïö©ÎÇ¥Ïó≠ Ï†ïÏÇ∞ Î≥¥Í≥†(10Ïõî,11Ïõî,12Ïõî)_2002907.html\n",
      "JSON ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB Ïó∞Í≤∞ ÏãúÏûë ===\n",
      "Host: localhost, Database: any_approval\n",
      "‚úì DB Ïó∞Í≤∞ ÏÑ±Í≥µ (FOUND_ROWS Î™®Îìú)\n",
      "\n",
      "=== Îç∞Ïù¥ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏ ÏãúÏûë (840Í±¥) ===\n",
      "  ÏßÑÌñâ: 100/840 (Îß§Ïπ≠: 100, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 200/840 (Îß§Ïπ≠: 200, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 300/840 (Îß§Ïπ≠: 300, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 400/840 (Îß§Ïπ≠: 400, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 500/840 (Îß§Ïπ≠: 500, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 600/840 (Îß§Ïπ≠: 600, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 700/840 (Îß§Ïπ≠: 700, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 800/840 (Îß§Ïπ≠: 800, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "  ÏßÑÌñâ: 840/840 (Îß§Ïπ≠: 840, ÏóÜÏùå: 0, Ïã§Ìå®: 0)\n",
      "\n",
      "=== Ïª§Î∞ã ÏãúÏûë ===\n",
      "‚úì Ïª§Î∞ã ÏôÑÎ£å\n",
      "\n",
      "=== Í≤∞Í≥º ÏöîÏïΩ ===\n",
      "‚úì Îß§Ïπ≠ ÏÑ±Í≥µ: 840Í±¥\n",
      "‚ö† DBÏóê ÏóÜÏùå: 0Í±¥\n",
      "‚úó Ïò§Î•ò: 0Í±¥\n",
      "\n",
      "‚úì DB Ïó∞Í≤∞ Ï¢ÖÎ£å\n",
      "==================================================\n",
      "\n",
      "ÏôÑÎ£å! Ï¥ù 840Í±¥ Ï≤òÎ¶¨Îê®\n"
     ]
    }
   ],
   "source": [
    "# drafter, createdAt, activitiesÎßå UPDATEÌïòÎäî Î≤ÑÏ†Ñ\n",
    "# ÌÖåÏù¥Î∏î Í∏∞Î∞ò Ï∂îÏ∂ú + CSV Ï°∞ÏßÅÎèÑ Îß§Ïπ≠ + Í≤∞Ïû¨ÏùòÍ≤¨ Ï∂îÍ∞Ä + KST ÏãúÍ∞ÑÎåÄ Ï≤òÎ¶¨\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz  # ‚Üê Ï∂îÍ∞Ä\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')  # ‚Üê Ï∂îÍ∞Ä: ÌïúÍµ≠ ÏãúÍ∞ÑÎåÄ\n",
    "        \n",
    "        # CSV Ï°∞ÏßÅÎèÑ Î°úÎìú\n",
    "        print(f\"üìä CSV Ï°∞ÏßÅÎèÑ Î°úÎìú Ï§ë... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ÏÇ¨ÏõêÎ™Ö']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['Î∂ÄÏÑú'],\n",
    "                'empNo': row['ÏÇ¨ÏõêÎ≤àÌò∏'] if pd.notna(row['ÏÇ¨ÏõêÎ≤àÌò∏']) else '',\n",
    "                'positionName': row['ÏßÅÏúÑ'] if pd.notna(row['ÏßÅÏúÑ']) else '',\n",
    "                'deptCode': row['Î∂ÄÏÑúÏΩîÎìú'] if pd.notna(row['Î∂ÄÏÑúÏΩîÎìú']) else ''\n",
    "            }\n",
    "        print(f\"‚úÖ Ï¥ù {len(self.employee_dict)}Î™Ö Î°úÎìú\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"ÌååÏùºÎ™ÖÏóêÏÑú ÎßàÏßÄÎßâ Ïà´Ïûê Ï∂îÏ∂ú\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"Ïù¥Î¶Ñ/ÏßÅÏ±Ö/Î∂ÄÏÑú ÌòïÏãùÏóêÏÑú Ï†ïÎ≥¥ Ï∂îÏ∂ú\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML ÌååÏùºÏóêÏÑú drafter, createdAt, activitiesÎßå Ï∂îÏ∂ú\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter Ï∂îÏ∂ú (ÌÖåÏù¥Î∏îÏóêÏÑú) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'Í∏∞ÏïàÏûê' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV Ï°∞ÏßÅÎèÑ Îß§Ïπ≠\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # Ìá¥ÏÇ¨Ïûê\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt Ï∂îÏ∂ú (ÌÖåÏù¥Î∏îÏóêÏÑú) - KST Ï≤òÎ¶¨ Ï∂îÍ∞Ä ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'Í∏∞ÏïàÏùº' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        # naive datetime ÏÉùÏÑ± ÌõÑ KSTÎ°ú Î™ÖÏãú\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities Ï∂îÏ∂ú (bg02ÏóêÏÑú) - KST Ï≤òÎ¶¨ Ï∂îÍ∞Ä ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # ÌÉÄÏûÖ Í≤∞Ï†ï\n",
    "                        if 'Í∏∞Ïïà' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'Ìï©Ïùò' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ÎÇ†Ïßú Î≥ÄÌôò (00:00:00) - KST Ï≤òÎ¶¨ Ï∂îÍ∞Ä\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV Ï°∞ÏßÅÎèÑ Îß§Ïπ≠\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # Ìá¥ÏÇ¨Ïûê\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ÏùºÎã® ÎπàÍ∞í\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment Ï∂îÍ∞Ä (user_spansÏóêÏÑú) ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ÏùòÍ≤¨ Ï∂îÏ∂ú - user_spanÏùò Î∂ÄÎ™®(td)ÏóêÏÑú div Ï∞æÍ∏∞\n",
    "                    action_comment = \"\"\n",
    "                    parent = user_span.parent\n",
    "                    if parent:\n",
    "                        comment_div = parent.find('div')\n",
    "                        if comment_div:\n",
    "                            action_comment = comment_div.get_text(strip=True)\n",
    "                    \n",
    "                    # activitiesÏóêÏÑú Ïù¥Î¶Ñ Ï∞æÏïÑÏÑú ÏùòÍ≤¨ Ï∂îÍ∞Ä\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # Í≤∞Í≥º Î∞òÌôò (ÌïÑÏöîÌïú 3Í∞ÄÏßÄÎßå)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"Î™®Îì† HTML ÌååÏùº Ï≤òÎ¶¨\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'Í≤∞Ïû¨'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"Í≤ΩÎ°úÎ•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"Ï¥ù {len(html_files)}Í∞úÏùò HTML ÌååÏùºÏùÑ Ï∞æÏïòÏäµÎãàÎã§.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"Ï≤òÎ¶¨ Ï§ë... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Ïò§Î•ò Î∞úÏÉù ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON ÌååÏùºÎ°ú Ï†ÄÏû•\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON ÌååÏùº Ï†ÄÏû• ÏôÑÎ£å: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB ÌäπÏ†ï Ïª¨ÎüºÎßå UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB Ïó∞Í≤∞ ÏãúÏûë ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB Ïó∞Í≤∞ - FOUND_ROWS ÌîåÎûòÍ∑∏ Ï∂îÍ∞Ä\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS  # ‚Üê Ï∂îÍ∞Ä!\n",
    "            )\n",
    "            print(\"‚úì DB Ïó∞Í≤∞ ÏÑ±Í≥µ (FOUND_ROWS Î™®Îìú)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ÏøºÎ¶¨\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== Îç∞Ïù¥ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏ ÏãúÏûë ({len(data)}Í±¥) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS Î™®Îìú: Îß§Ïπ≠Îêú Ìñâ Ïàò Î∞òÌôò (Î≥ÄÍ≤Ω Ïó¨Î∂Ä Î¨¥Í¥Ä)\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ÏßÑÌñâ: {idx}/{len(data)} (Îß§Ïπ≠: {success_count}, ÏóÜÏùå: {not_found_count}, Ïã§Ìå®: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [Ïò§Î•ò {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== Ïª§Î∞ã ÏãúÏûë ===\")\n",
    "            conn.commit()\n",
    "            print(\"‚úì Ïª§Î∞ã ÏôÑÎ£å\")\n",
    "            \n",
    "            print(f\"\\n=== Í≤∞Í≥º ÏöîÏïΩ ===\")\n",
    "            print(f\"‚úì Îß§Ïπ≠ ÏÑ±Í≥µ: {success_count}Í±¥\")\n",
    "            print(f\"‚ö† DBÏóê ÏóÜÏùå: {not_found_count}Í±¥\")\n",
    "            print(f\"‚úó Ïò§Î•ò: {error_count}Í±¥\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\n‚ö† DBÏóêÏÑú Î™ª Ï∞æÏùÄ source_id ÏÉòÌîå (Ï≤òÏùå 20Í∞ú):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nüìä DBÏùò source_id Î≤îÏúÑ: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nÏ≤òÏùå 5Í∞ú Ïô∏ {error_count - 5}Í∞úÏùò Ï∂îÍ∞Ä Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\")\n",
    "                print(\"Î™®Îì† Ïò§Î•ò Î≥¥Í∏∞:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... Ïô∏ {len(error_details) - 20}Í∞ú Îçî\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\n‚ùå DB Ïò§Î•ò Î∞úÏÉù:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå ÏùºÎ∞ò Ïò§Î•ò Î∞úÏÉù: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\n‚úì DB Ïó∞Í≤∞ Ï¢ÖÎ£å\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html'\n",
    "    end_year = 2015\n",
    "    csv_file = 'Ïù∏ÏÇ¨Ï†ïÎ≥¥_Î∂ÄÏÑúÏΩîÎìúÏ∂îÍ∞Ä.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML ÌååÏùº ÌååÏã± ÏãúÏûë...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nÏôÑÎ£å! Ï¥ù {len(results)}Í±¥ Ï≤òÎ¶¨Îê®\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
