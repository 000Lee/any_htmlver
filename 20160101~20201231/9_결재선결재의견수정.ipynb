{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9cd056-97ee-4ca0-829b-63e9a0e6683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 7704ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/7704] 20160204_íœ´ê°€ í’ˆì˜_2009595.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/7704] 20160307_íœ´ê°€ í’ˆì˜_2009690.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/7704] 20160401_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³  - í˜„ê´‘ì„­(2016.03)_2989353.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/7704] 20160426_ëŒ€ì „ìˆ™ì†Œ(ì„¸ì¢…ì•„íŒŒíŠ¸) 2016ë…„ 3ì›” ê´€ë¦¬ë¹„_3093067.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/7704] 20160524_êµ­ë¯¼ê¶Œìµìœ„ì›íšŒ 5ì›” ì‚¬ê¸°ì§„ì‘ë¹„ í’ˆì˜ì‹ ì²­_3172052.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/7704] 20160620_ì—°ì°¨íœ´ê°€ì‚¬ìš© í’ˆì˜(6_21)_3253028.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/7704] 20160720_[ì™¸ì£¼ì¸ë ¥íˆ¬ì…ê³„ì•½í’ˆì˜] LGí™”í™• ê¸°ìˆ ì› ë¹„ë¬¸ê´€ë¦¬ì²´ê³„ ê°œì„ (ì´ëˆê²½)_5600251.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/7704] 20160812_ì—¬ë¦„íœ´ê°€ í’ˆì˜_5807435.html\n",
      "ì²˜ë¦¬ ì¤‘... [900/7704] 20160908_ì‹ ìš©ë³´ì¦ê¸°ê¸ˆ HPì¥ë¹„ë‚©í’ˆ_5953879.html\n",
      "ì²˜ë¦¬ ì¤‘... [1000/7704] 20161010_ì¥ê¸°ì¶œì¥ í’ˆì˜ì„œ ê¸°ì•ˆì˜¬ë¦½ë‹ˆë‹¤._6136837.html\n",
      "ì²˜ë¦¬ ì¤‘... [1100/7704] 20161025_10-28 NHN Mo, PC x4_6220679.html\n",
      "ì²˜ë¦¬ ì¤‘... [1200/7704] 20161109_11-14 ë‹¤ìš° PC, NB x14ëŒ€_6311294.html\n",
      "ì²˜ë¦¬ ì¤‘... [1300/7704] 20161128_2016ë…„ 11ì›” ë²•ì¸ì¹´ë“œ ì‚¬ìš© í’ˆì˜_6513503.html\n",
      "ì²˜ë¦¬ ì¤‘... [1400/7704] 20161213_ë²•ì¸ì°¨ëŸ‰(34ì˜¤9405)íƒ€ì´ì–´ì™¸ ë¶€í’ˆêµì²´ë¹„ìš© ì§€ê¸‰ìš”ì²­_6638142.html\n",
      "ì²˜ë¦¬ ì¤‘... [1500/7704] 20161227_íœ´ê°€ í’ˆì˜_6717081.html\n",
      "ì²˜ë¦¬ ì¤‘... [1600/7704] 20170117_[ì™¸ì£¼ì¸ë ¥íˆ¬ì…ê³„ì•½í’ˆì˜] ETRI ê¸°ìˆ ê°€ì¹˜í‰ê°€ ì§€ì› ì‹œìŠ¤í…œ ê³ ë„í™”_ë°˜ì‘í˜• ì›¹ ë° í¼ë¸”ë¦¬ì‹± (ê¹€ë‚˜ì—°)_6841140.html\n",
      "ì²˜ë¦¬ ì¤‘... [1700/7704] 20170206_ë™ìš°í™”ì¸ì¼ ë‹¨ê¸°ì¶œì¥ í’ˆì˜_6944314.html\n",
      "ì²˜ë¦¬ ì¤‘... [1800/7704] 20170224_02-27 DCT Server x4ëŒ€_7053637.html\n",
      "ì²˜ë¦¬ ì¤‘... [1900/7704] 20170314_03-12 NHN Monitor x 7ëŒ€_7155436.html\n",
      "ì²˜ë¦¬ ì¤‘... [2000/7704] 20170327_ìœ í‹¸ë ‰ìŠ¤ ì „ìì—°êµ¬ë…¸íŠ¸ íšŒì‹ë¹„ ì§€ì› ìš”ì²­_7225928.html\n",
      "ì²˜ë¦¬ ì¤‘... [2100/7704] 20170410_[ë¹„ìš©ì‚¬ìš©í’ˆì˜] 17ë…„ ì¶˜ê³„í–‰ì‚¬ ì²´ìœ¡ëŒ€íšŒ ì œë°˜ ë¹„ìš© ì‚¬ìš© í’ˆì˜ ê±´_7316723.html\n",
      "ì²˜ë¦¬ ì¤‘... [2200/7704] 20170426_SKí…”ë ˆì½¤ ì—…ì²´ë“±ë¡ì„ ìœ„í•œ ì‹ ìš©í‰ê°€ í’ˆì˜_7417083.html\n",
      "ì²˜ë¦¬ ì¤‘... [2300/7704] 20170517_5_19ì¼ íœ´ê°€ ìš”ì²­ë“œë¦½ë‹ˆë‹¤._7517404.html\n",
      "ì²˜ë¦¬ ì¤‘... [2400/7704] 20170601_LGí™”í•™ ìƒí‘œê´€ë¦¬ëª¨ë“ˆ êµ¬ì¶• ê³„ì•½ í’ˆì˜_7612371.html\n",
      "ì²˜ë¦¬ ì¤‘... [2500/7704] 20170620_[ëŒ€ê¸ˆê²°ì œ] ì™¸ì£¼ìš©ì—­ë¹„ ëŒ€ê¸ˆ ê²°ì œì˜ ê±´ (6_26ì)_7716954.html\n",
      "ì²˜ë¦¬ ì¤‘... [2600/7704] 20170707_ì„œìš¸ ê¸°ìˆ™ì‚¬(ì˜ˆì„±ì˜¤í”¼ìŠ¤í…”) 6ì›” ë„ì‹œê°€ìŠ¤ë¹„ í’ˆì˜_7829119.html\n",
      "ì²˜ë¦¬ ì¤‘... [2700/7704] 20170726_í•˜ê³„íœ´ê°€ ë° ë¦¬í”„ë˜ì‰¬ íœ´ê°€ í’ˆì˜_7947662.html\n",
      "ì²˜ë¦¬ ì¤‘... [2800/7704] 20170816_08-13 NHN Monitor x 20ëŒ€_8057843.html\n",
      "ì²˜ë¦¬ ì¤‘... [2900/7704] 20170906_[ëŒ€ê¸ˆê²°ì œ] BNKê¸ˆìœµê·¸ë£¹ ITì„¼í„°ì´ì „ ì§€ì›ì„œë¹„ìŠ¤ ë§¤ì… ëŒ€ê¸ˆ ê²°ì œì˜ ê±´(ì¼ì‹œë¶ˆ) - ë””ë¦¬ì•„_8182752.html\n",
      "ì²˜ë¦¬ ì¤‘... [3000/7704] 20170925_ì—°ì°¨ íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤._8291960.html\n",
      "ì²˜ë¦¬ ì¤‘... [3100/7704] 20171019_ì™¸ì£¼ì¸ì› íˆ¬ì… í’ˆì˜ -í•œêµ­ì½˜í…ì¸ ì§„í¥ì› ì‚¬ì—…ê´€ë¦¬ì‹œìŠ¤í…œ(ë³€ì² ìˆ˜)_8406872.html\n",
      "ì²˜ë¦¬ ì¤‘... [3200/7704] 20171108_11-12 NHN PC, Monitor x 20_8528068.html\n",
      "ì²˜ë¦¬ ì¤‘... [3300/7704] 20171128_[ëŒ€ê¸ˆê²°ì œ] 11ì›” ì§€ê¸‰ë³´ë¥˜ ì™¸ì£¼ìš©ì—­ë¹„ ëŒ€ê¸ˆ ê²°ì œì˜ ê±´ - ì—°ìŠ¹í›ˆ(ì´ì—°ì†Œí”„íŠ¸ë±…í¬)_8643391.html\n",
      "ì²˜ë¦¬ ì¤‘... [3400/7704] 20171218_ì‚¼ì„±SDI '18ë…„ ì§€ì‹ì¬ì‚°ê´€ë¦¬ì‹œìŠ¤í…œ ìœ ì§€ë³´ìˆ˜ ê³„ì•½_8764948.html\n",
      "ì²˜ë¦¬ ì¤‘... [3500/7704] 20180103_[ëŒ€ê¸ˆê²°ì œ] IIPCìœ„ì›íšŒ ì‚¬ë¬´ì‹¤ ì„ëŒ€ì˜ ê±´_8853115.html\n",
      "ì²˜ë¦¬ ì¤‘... [3600/7704] 20180125_01-36 ì´ëœë“œ NB, Part x 26ëŒ€_8984249.html\n",
      "ì²˜ë¦¬ ì¤‘... [3700/7704] 20180220_02-29 ë‹¤ìš°ê¸°ìˆ  Part x 8ëŒ€_9123453.html\n",
      "ì²˜ë¦¬ ì¤‘... [3800/7704] 20180307_í•œí™”í† íƒˆ ê³¼ì œê´€ë¦¬ì‹œìŠ¤í…œ ì¥ê¸°ì¶œì¥ í’ˆì˜_9214593.html\n",
      "ì²˜ë¦¬ ì¤‘... [3900/7704] 20180328_ì¬ì§ì¦ëª…ì„œ ë° 4ëŒ€ë³´í—˜ê°€ì…í™•ì¸ì„¸ ìš”ì²­_9333590.html\n",
      "ì²˜ë¦¬ ì¤‘... [4000/7704] 20180413_ë™ìš°í™”ì¸ì¼ ì¶œì¥ ê²½ë¹„ í’ˆì˜_9438827.html\n",
      "ì²˜ë¦¬ ì¤‘... [4100/7704] 20180502_íœ´ê°€ì‚¬ìš©ì‹ ì²­ì„œ_9548865.html\n",
      "ì²˜ë¦¬ ì¤‘... [4200/7704] 20180523_05-34 Atsys Server, Part x 3ëŒ€_9661732.html\n",
      "ì²˜ë¦¬ ì¤‘... [4300/7704] 20180612_[ëŒ€ê¸ˆê²°ì œ] ìš”ë‹¤ì •ë³´ê¸°ìˆ  &quot;BNKê¸ˆìœµê·¸ë£¹ ë°ì´íƒ€ì„¼í„° ì´ì „&quot; ì‚¬ì—… ë§¤ì… ëŒ€ê¸ˆ ê²°ì œì˜ ê±´ - ì•ˆë•ê¸°(í”„ë¦¬ëœì„œ)_9782379.html\n",
      "ì²˜ë¦¬ ì¤‘... [4400/7704] 20180702_ëŒ€ì „ì§€ì‚¬ ìœ¤ì„í˜„ 6ì›” ì•¼ê·¼ì‹ëŒ€ ì§€ê¸‰ ì‹ ì²­ì„œ í’ˆì˜_9894660.html\n",
      "ì²˜ë¦¬ ì¤‘... [4500/7704] 20180724_07-29 NHN Monitor x 28_10028745.html\n",
      "ì²˜ë¦¬ ì¤‘... [4600/7704] 20180814_ì¶œì¥ë¹„ ì§€ê¸‰ ì‹ ì²­_10148245.html\n",
      "ì²˜ë¦¬ ì¤‘... [4700/7704] 20180905_ì œì¦ëª…ì„œ ë°œê¸‰ ì‹ ì²­_10275112.html\n",
      "ì²˜ë¦¬ ì¤‘... [4800/7704] 20181004_10-04 NHN PC, Monitor x 25_10430441.html\n",
      "ì²˜ë¦¬ ì¤‘... [4900/7704] 20181101_íœ´ê°€ ì‚¬ìš© ì‹ ì²­ì„œ_ìµœíƒœì˜_2018.11.02(ê¸ˆ)_10592726.html\n",
      "ì²˜ë¦¬ ì¤‘... [5000/7704] 20181129_11-34 Atsys Server x 1_10768183.html\n",
      "ì²˜ë¦¬ ì¤‘... [5100/7704] 20181220_20181217 ì•¼ê·¼ íƒì‹œë¹„ ì²­êµ¬_10900148.html\n",
      "ì²˜ë¦¬ ì¤‘... [5200/7704] 20190121_ì—°ì°¨ íœ´ê°€ í’ˆì˜ì„œ_11082463.html\n",
      "ì²˜ë¦¬ ì¤‘... [5300/7704] 20190215_[ëŒ€ê¸ˆê²°ì œ] ì™¸ì£¼ìš©ì—­ë¹„ ëŒ€ê¸ˆ ê²°ì œì˜ ê±´ - í”„ë¦¬ëœì„œ(02_15ì¼ì)_11220276.html\n",
      "ì²˜ë¦¬ ì¤‘... [5400/7704] 20190315_ë™ìš°í™”ì¸ì¼ ì¶œì¥ êµí†µë¹„ ì§€ê¸‰ í’ˆì˜_11388981.html\n",
      "ì²˜ë¦¬ ì¤‘... [5500/7704] 20190411_íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤._11557088.html\n",
      "ì²˜ë¦¬ ì¤‘... [5600/7704] 20190502_[SKì¼€ë¯¸ì¹¼ íŠ¹í—ˆì‹œìŠ¤í…œ]4ì›” ì•¼ê·¼ì‹ëŒ€ë¥¼ ì‹ ì²­í•©ë‹ˆë‹¤._11682126.html\n",
      "ì²˜ë¦¬ ì¤‘... [5700/7704] 20190531_ì¶œì¥ë¹„ ì§€ê¸‰ ì‹ ì²­ì„œ_11853210.html\n",
      "ì²˜ë¦¬ ì¤‘... [5800/7704] 20190621_ì—°ì°¨íœ´ê°€ í’ˆì˜_11979063.html\n",
      "ì²˜ë¦¬ ì¤‘... [5900/7704] 20190717_ê¸°íƒ€ê²½ë¹„ ì‹ ì²­ì˜ ê±´_12139665.html\n",
      "ì²˜ë¦¬ ì¤‘... [6000/7704] 20190808_ì—¬ë¦„íœ´ê°€ì‚¬ìš©ì‹ ì²­_12265760.html\n",
      "ì²˜ë¦¬ ì¤‘... [6100/7704] 20190830_[ëŒ€ê¸ˆê²°ì œ] &quot;í´ë¼ìš°ë“œê¸°ë°˜ ë¶€í’ˆì •ë³´ì„œë¹„ìŠ¤ì œê³µ ì„œë²„&quot; êµ­ë‚´íŠ¹í—ˆì¶œì› ì˜ê²¬_ë³´ì •ì„œ ì œì¶œ ìˆ˜ìˆ˜ë£Œ ë° ê´€ë‚©ë£Œ_12391076.html\n",
      "ì²˜ë¦¬ ì¤‘... [6200/7704] 20190927_09-26 NHN WS, PC, Monitor x 14_12547871.html\n",
      "ì²˜ë¦¬ ì¤‘... [6300/7704] 20191018_íƒì‹œë¹„ ì§€ê¸‰ í’ˆì˜_12669479.html\n",
      "ì²˜ë¦¬ ì¤‘... [6400/7704] 20191108_ëŒ€ì „ í•­ê³µìš°ì£¼ì—°êµ¬ì› ì¶œì¥ë¹„ ì§€ê¸‰ ì‹ ì²­_12797105.html\n",
      "ì²˜ë¦¬ ì¤‘... [6500/7704] 20191129_í•œí™”ì‹œìŠ¤í…œ ì§€ì‹ì¬ì‚°ê´€ë¦¬ ì‹œìŠ¤í…œ ìš©ì—­ ê¶Œíƒœìš± íˆ¬ì… í’ˆì˜ ì‘ì„±_12924695.html\n",
      "ì²˜ë¦¬ ì¤‘... [6600/7704] 20191227_2019.12.31(í™”) ì—°ì°¨ í’ˆì˜_13096662.html\n",
      "ì²˜ë¦¬ ì¤‘... [6700/7704] 20200121_ì—°ì°¨íœ´ê°€ ì‚¬ìš©ì‹ ì²­_13231308.html\n",
      "ì²˜ë¦¬ ì¤‘... [6800/7704] 20200229_ì•¼ê·¼ì‹ëŒ€ ì§€ê¸‰ ì‹ ì²­ë“œë¦½ë‹ˆë‹¤._13449955.html\n",
      "ì²˜ë¦¬ ì¤‘... [6900/7704] 20200331_2020ë…„ 2ì›” ì•¼ê·¼ì‹ëŒ€ ì§€ê¸‰ ì‹ ì²­ì„œ í’ˆì˜ ì‘ì„±_13621964.html\n",
      "ì²˜ë¦¬ ì¤‘... [7000/7704] 20200503_ì•¼ê·¼ì‹ëŒ€ ì§€ê¸‰ ì‹ ì²­ì„œ_13790052.html\n",
      "ì²˜ë¦¬ ì¤‘... [7100/7704] 20200612_íœ´ê°€ ì‚¬ìš© ì‹ ì²­ì„œ_14014529.html\n",
      "ì²˜ë¦¬ ì¤‘... [7200/7704] 20200724_'20.07.24 ì—°ì°¨í’ˆì˜_14248756.html\n",
      "ì²˜ë¦¬ ì¤‘... [7300/7704] 20200828_ê¹€ìƒìš± ë°˜ì°¨ ì…ë‹ˆë‹¤._14440221.html\n",
      "ì²˜ë¦¬ ì¤‘... [7400/7704] 20201019_[ëŒ€ê¸ˆê²°ì œ] ETRI í†µí•©ì •ë³´(ETRIware) ìœ ì§€ê´€ë¦¬ ê³„ì•½ - 2020ë…„ 9ì›”ë¶„ ëŒ€ê¸ˆ ì§€ê¸‰ì˜ ê±´_14705552.html\n",
      "ì²˜ë¦¬ ì¤‘... [7500/7704] 20201111_LG U+ MECê¸°ë°˜ 5G í”Œë«í¼ êµ¬ì¶•_ì„ íˆ¬ì… í’ˆì˜_14856103.html\n",
      "ì²˜ë¦¬ ì¤‘... [7600/7704] 20201208_íœ´ê°€ ì‹ ì²­_15018001.html\n",
      "ì²˜ë¦¬ ì¤‘... [7700/7704] 20201230_í‡´ì§ í’ˆì˜ì„œ_15147253.html\n",
      "ì²˜ë¦¬ ì¤‘... [7704/7704] 20201231_ì¶œì¥ë¹„ ì§€ê¸‰ ì‹ ì²­í•©ë‹ˆë‹¤._15155817.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (7704ê±´) ===\n",
      "  ì§„í–‰: 100/7704 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/7704 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/7704 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/7704 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/7704 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/7704 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/7704 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/7704 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 900/7704 (ë§¤ì¹­: 900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1000/7704 (ë§¤ì¹­: 1000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1100/7704 (ë§¤ì¹­: 1100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1200/7704 (ë§¤ì¹­: 1200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1300/7704 (ë§¤ì¹­: 1300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1400/7704 (ë§¤ì¹­: 1400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1500/7704 (ë§¤ì¹­: 1500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1600/7704 (ë§¤ì¹­: 1600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1700/7704 (ë§¤ì¹­: 1700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1800/7704 (ë§¤ì¹­: 1800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1900/7704 (ë§¤ì¹­: 1900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2000/7704 (ë§¤ì¹­: 2000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2100/7704 (ë§¤ì¹­: 2100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2200/7704 (ë§¤ì¹­: 2200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2300/7704 (ë§¤ì¹­: 2300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2400/7704 (ë§¤ì¹­: 2400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2500/7704 (ë§¤ì¹­: 2500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2600/7704 (ë§¤ì¹­: 2600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2700/7704 (ë§¤ì¹­: 2700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2800/7704 (ë§¤ì¹­: 2800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2900/7704 (ë§¤ì¹­: 2900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3000/7704 (ë§¤ì¹­: 3000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3100/7704 (ë§¤ì¹­: 3100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3200/7704 (ë§¤ì¹­: 3200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3300/7704 (ë§¤ì¹­: 3300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3400/7704 (ë§¤ì¹­: 3400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3500/7704 (ë§¤ì¹­: 3500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3600/7704 (ë§¤ì¹­: 3600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3700/7704 (ë§¤ì¹­: 3700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3800/7704 (ë§¤ì¹­: 3800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3900/7704 (ë§¤ì¹­: 3900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4000/7704 (ë§¤ì¹­: 4000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4100/7704 (ë§¤ì¹­: 4100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4200/7704 (ë§¤ì¹­: 4200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4300/7704 (ë§¤ì¹­: 4300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4400/7704 (ë§¤ì¹­: 4400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4500/7704 (ë§¤ì¹­: 4500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4600/7704 (ë§¤ì¹­: 4600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4700/7704 (ë§¤ì¹­: 4700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4800/7704 (ë§¤ì¹­: 4800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4900/7704 (ë§¤ì¹­: 4900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5000/7704 (ë§¤ì¹­: 5000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5100/7704 (ë§¤ì¹­: 5100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5200/7704 (ë§¤ì¹­: 5200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5300/7704 (ë§¤ì¹­: 5300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5400/7704 (ë§¤ì¹­: 5400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5500/7704 (ë§¤ì¹­: 5500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5600/7704 (ë§¤ì¹­: 5600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5700/7704 (ë§¤ì¹­: 5700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5800/7704 (ë§¤ì¹­: 5800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5900/7704 (ë§¤ì¹­: 5900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6000/7704 (ë§¤ì¹­: 6000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6100/7704 (ë§¤ì¹­: 6100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6200/7704 (ë§¤ì¹­: 6200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6300/7704 (ë§¤ì¹­: 6300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6400/7704 (ë§¤ì¹­: 6400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6500/7704 (ë§¤ì¹­: 6500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6600/7704 (ë§¤ì¹­: 6600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6700/7704 (ë§¤ì¹­: 6700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6800/7704 (ë§¤ì¹­: 6800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6900/7704 (ë§¤ì¹­: 6900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7000/7704 (ë§¤ì¹­: 7000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7100/7704 (ë§¤ì¹­: 7100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7200/7704 (ë§¤ì¹­: 7200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7300/7704 (ë§¤ì¹­: 7300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7400/7704 (ë§¤ì¹­: 7400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7500/7704 (ë§¤ì¹­: 7500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7600/7704 (ë§¤ì¹­: 7600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7700/7704 (ë§¤ì¹­: 7700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7704/7704 (ë§¤ì¹­: 7704, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 7704ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 7704ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "#actionComment  ì¶”ì¶œ ê°œì„ \n",
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\"\"\"\n",
    " [ê¸°ëŠ¥]\n",
    " HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë¥¼ ì¬ì¶”ì¶œí•˜ì—¬\n",
    " DB documents í…Œì´ë¸”ì˜ í•´ë‹¹ ì»¬ëŸ¼ë§Œ UPDATE\n",
    " (í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€)\n",
    "\n",
    " [ì¶”ì¶œ ëŒ€ìƒ]\n",
    " - drafter: ê¸°ì•ˆì ì •ë³´ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì\" í–‰ì—ì„œ)\n",
    " - createdAt: ê¸°ì•ˆì¼ì‹œ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì¼\" í–‰ì—ì„œ, KSTâ†’Unix ms)\n",
    " - activities: ê²°ì¬ í™œë™ ë¡œê·¸ (bg02 divì—ì„œ)\n",
    "   - actionComment: user_spansì—ì„œ ì¶”ê°€ ì¶”ì¶œ\n",
    "\n",
    " [CSV ì¡°ì§ë„ ë§¤ì¹­]\n",
    " - í˜„ì§ì: CSVì—ì„œ positionName, deptName, emailId, deptCode ë§¤ì¹­\n",
    " - í‡´ì‚¬ì: emailIdë¥¼ 'master'ë¡œ ì„¤ì •, ë‚˜ë¨¸ì§€ ê³µë€\n",
    "\n",
    " [activities ì¶”ì¶œ ë¡œì§]\n",
    " 1. bg02 div ë‚´ ul > liì—ì„œ ì´ë¦„, íƒ€ì…, ë‚ ì§œ ì¶”ì¶œ\n",
    " 2. íƒ€ì… ê²°ì •: ê¸°ì•ˆâ†’DRAFT, í•©ì˜â†’AGREEMENT, ê·¸ì™¸â†’APPROVAL\n",
    " 3. ë‚ ì§œ: MM/DD í˜•ì‹ â†’ createdAt ì—°ë„ + KST ë³€í™˜\n",
    " 4. actionComment: user_spans ìˆœíšŒí•˜ë©° ë‹¤ìŒ divì—ì„œ ì˜ê²¬ ì¶”ì¶œ\n",
    "\n",
    " [ì‹œê°„ëŒ€ ì²˜ë¦¬]\n",
    " - ëª¨ë“  ë‚ ì§œë¥¼ KST(Asia/Seoul)ë¡œ ì²˜ë¦¬ í›„ Unix timestamp ë³€í™˜\n",
    "\n",
    " [ë™ì‘ ìˆœì„œ]\n",
    " 1. CSV ì¡°ì§ë„ ë¡œë“œ\n",
    " 2. HTML í´ë”ì—ì„œ íŒŒì¼ ìˆœíšŒ\n",
    " 3. ê° HTMLì—ì„œ drafter, createdAt, activities ì¶”ì¶œ\n",
    " 4. JSON íŒŒì¼ë¡œ ì €ì¥\n",
    " 5. DB UPDATE (source_id + end_yearë¡œ ë§¤ì¹­)\n",
    "\n",
    " [ì¶œë ¥]\n",
    " - JSON íŒŒì¼: update_drafter_activities.json\n",
    " - MariaDB: documents í…Œì´ë¸”ì˜ drafter_*, created_at, activities ì»¬ëŸ¼ UPDATE\n",
    "\n",
    " [ì„¤ì • (#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)]\n",
    " - base_path: HTML í´ë” ê²½ë¡œ\n",
    " - end_year: ëŒ€ìƒ ì—°ë„ (WHERE ì¡°ê±´)\n",
    " - csv_file: ì¸ì‚¬ì •ë³´ CSV íŒŒì¼\n",
    " - db_config: DB ì ‘ì† ì •ë³´\n",
    "\n",
    " [ì˜ì¡´ì„±]\n",
    " - beautifulsoup4\n",
    " - pymysql\n",
    " - pandas\n",
    " - pytz\n",
    " -> pip install beautifulsoup4 pymysql pandas pytz\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) - ê°œì„ ë¨ ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_span ì´í›„ ë‹¤ìŒ user_span ì „ê¹Œì§€ì˜ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    \n",
    "                    # next_siblingsë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ íƒìƒ‰\n",
    "                    for sibling in user_span.next_siblings:\n",
    "                        # ë‹¤ìŒ user_spanì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨\n",
    "                        if hasattr(sibling, 'name'):\n",
    "                            if sibling.name == 'span' and 'user' in sibling.get('class', []):\n",
    "                                break\n",
    "                            # divë¥¼ ì°¾ìœ¼ë©´ ì €ì¥í•˜ê³  ì¤‘ë‹¨\n",
    "                            if sibling.name == 'div':\n",
    "                                action_comment = sibling.get_text(strip=True)\n",
    "                                break\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2016-01-01~2020-12-31\\html'\n",
    "    end_year = 2020\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b6a8c8-db98-4d35-bffd-1c5ebacde3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 840ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/840] 20100225_ì—°ì°¨íœ´ê°€(3_2) ì‹ ì²­í•©ë‹ˆë‹¤._2002163.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/840] 20100401_[ê¸°ìˆ ì§€ì›íŒ€ ê²©ë ¤ ì¸ì„¼í‹°ë¸Œ ì§€ê¸‰í’ˆì˜]_2002268.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/840] 20100517_ê°œì¸íœ´ê°€í’ˆì˜_2002367.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/840] 20100705_íŒŒì¼ì„œë²„ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­_2002467.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/840] 20100817_8ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ê¸°ìˆ ì§€ì›ë¶€ë¬¸_2002570.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/840] 20100929_ì¬ì§ì¦ëª…ì„œ ë°œê¸‰ìš”ì²­_2002666.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/840] 20101110_ëŒ€ì „ì§€ì‚¬ ê³µìš© í•˜ë“œë””ìŠ¤í¬ êµ¬ë§¤ ìš”ì²­_2002767.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/840] 20101221_12ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ì „ë¬¸ê°€Gr.(ê¹€ê·œì¼)_2002865.html\n",
      "ì²˜ë¦¬ ì¤‘... [840/840] 20101231_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (10ì›”,11ì›”,12ì›”)_2002907.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (840ê±´) ===\n",
      "  ì§„í–‰: 100/840 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/840 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/840 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/840 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/840 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/840 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/840 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/840 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 840/840 (ë§¤ì¹­: 840, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 840ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 840ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz  # â† ì¶”ê°€\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')  # â† ì¶”ê°€: í•œêµ­ ì‹œê°„ëŒ€\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        # naive datetime ìƒì„± í›„ KSTë¡œ ëª…ì‹œ\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬ ì¶”ê°€\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_spanì˜ ë¶€ëª¨(td)ì—ì„œ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    parent = user_span.parent\n",
    "                    if parent:\n",
    "                        comment_div = parent.find('div')\n",
    "                        if comment_div:\n",
    "                            action_comment = comment_div.get_text(strip=True)\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS  # â† ì¶”ê°€!\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜ (ë³€ê²½ ì—¬ë¶€ ë¬´ê´€)\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html'\n",
    "    end_year = 2015\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
