{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4605c73f-6f79-4916-b566-11ff6da40484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "총 처리: 840건\n",
      "✓ 모든 제목 일치\n",
      "처리 완료!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# 상태 매핑 딕셔너리\n",
    "STATUS_MAP = {\n",
    "    '기안': 'DRAFT',\n",
    "    '승인': 'APPROVAL',\n",
    "    '합의': 'AGREEMENT'\n",
    "}\n",
    "\n",
    "def extract_document_id(source_id):\n",
    "    \"\"\"sourceId에서 document_id 추출 (예: doc_2985802_02 → 2985802)\"\"\"\n",
    "    match = re.search(r'doc_(\\d+)_', source_id)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def parse_approval_date(date_str):\n",
    "    \"\"\"날짜 문자열을 유닉스 타임스탬프 밀리초로 변환\"\"\"\n",
    "    dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(dt.timestamp() * 1000)\n",
    "\n",
    "def process_cmds(csv_file, input_cmds, output_cmds):\n",
    "    # CSV 파일 읽기\n",
    "    csv_data = {}\n",
    "    with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            doc_id = row['document_id']\n",
    "            if doc_id not in csv_data:\n",
    "                csv_data[doc_id] = []\n",
    "            csv_data[doc_id].append(row)\n",
    "    \n",
    "    # 불일치 리스트\n",
    "    mismatch_list = []\n",
    "    line_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    # CMDS 파일 처리\n",
    "    with open(input_cmds, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(output_cmds, 'w', encoding='utf-8') as f_out:\n",
    "        \n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            line_count += 1\n",
    "            \n",
    "            # 진행상황 표시 (1000건마다)\n",
    "            if line_count % 1000 == 0:\n",
    "                print(f'처리 중... {line_count}건')\n",
    "            \n",
    "            # \"addDocument \" 접두어 제거\n",
    "            if line.startswith('addDocument '):\n",
    "                json_str = line[12:]  # \"addDocument \" 는 12글자\n",
    "            else:\n",
    "                json_str = line\n",
    "            \n",
    "            # JSON 파싱 (에러 처리 추가)\n",
    "            try:\n",
    "                data = json.loads(json_str)\n",
    "            except json.JSONDecodeError as e:\n",
    "                error_count += 1\n",
    "                print(f'\\n⚠️ JSON 파싱 에러 (줄 {line_count}): {str(e)}')\n",
    "                print(f'   문제 줄 미리보기: {line[:100]}...')\n",
    "                # 파싱 실패한 줄은 원본 그대로 출력\n",
    "                f_out.write(line + '\\n')\n",
    "                continue\n",
    "            \n",
    "            # sourceId에서 document_id 추출\n",
    "            source_id = data.get('sourceId', '')\n",
    "            doc_id = extract_document_id(source_id)\n",
    "            \n",
    "            if doc_id and doc_id in csv_data:\n",
    "                csv_rows = csv_data[doc_id]\n",
    "                \n",
    "                # 제목 비교 (CMDS의 title vs CSV의 post_title)\n",
    "                cmds_title = data.get('title', '')\n",
    "                csv_title = csv_rows[0]['post_title']\n",
    "                \n",
    "                if cmds_title != csv_title:\n",
    "                    # 제목 불일치 - 리스트에 추가하고 원본 그대로 출력\n",
    "                    mismatch_list.append({\n",
    "                        'doc_id': doc_id,\n",
    "                        'cmds_title': cmds_title,\n",
    "                        'csv_title': csv_title\n",
    "                    })\n",
    "                    output_line = 'addDocument ' + json.dumps(data, ensure_ascii=False, separators=(',', ':'))\n",
    "                    f_out.write(output_line + '\\n')\n",
    "                    continue\n",
    "                \n",
    "                # 제목 일치 - activities 업데이트\n",
    "                for activity in data.get('activities', []):\n",
    "                    activity_type = activity.get('type', '')\n",
    "                    activity_name = activity.get('name', '')\n",
    "                    \n",
    "                    # CSV에서 매칭되는 행 찾기\n",
    "                    for csv_row in csv_rows:\n",
    "                        csv_status = STATUS_MAP.get(csv_row['status'], '')\n",
    "                        csv_approver = csv_row['approver']\n",
    "                        \n",
    "                        # type과 name이 모두 일치하는지 확인\n",
    "                        if (activity_type == csv_status and \n",
    "                            activity_name in csv_approver):\n",
    "                            \n",
    "                            # actionDate 업데이트\n",
    "                            approval_date = csv_row['approval_date']\n",
    "                            activity['actionDate'] = parse_approval_date(approval_date)\n",
    "                            break\n",
    "            \n",
    "            # JSON을 한 줄로 변환하여 출력 (addDocument 접두어 포함)\n",
    "            output_line = 'addDocument ' + json.dumps(data, ensure_ascii=False, separators=(',', ':'))\n",
    "            f_out.write(output_line + '\\n')\n",
    "    \n",
    "    # 처리 완료 후 로그 출력\n",
    "    print(f'\\n총 처리: {line_count}건')\n",
    "    if error_count > 0:\n",
    "        print(f'⚠️ JSON 파싱 에러: {error_count}건')\n",
    "    \n",
    "    if len(mismatch_list) > 0:\n",
    "        # 불일치가 있으면 항상 파일로 저장\n",
    "        with open('title_mismatch.log', 'w', encoding='utf-8') as log:\n",
    "            for item in mismatch_list:\n",
    "                log.write(f\"Doc ID: {item['doc_id']}\\n\")\n",
    "                log.write(f\"CMDS title: {item['cmds_title']}\\n\")\n",
    "                log.write(f\"CSV post_title: {item['csv_title']}\\n\\n\")\n",
    "        print(f'⚠️ 제목 불일치: {len(mismatch_list)}건 (title_mismatch.log 파일 확인)')\n",
    "    else:\n",
    "        print('✓ 모든 제목 일치')\n",
    "\n",
    "# 실행\n",
    "if __name__ == '__main__':\n",
    "    csv_file = r\"C:\\Users\\LEEJUHWAN\\Downloads\\crawling_approval_data_2010.csv\"  # CSV 파일 경로\n",
    "    input_cmds = r\"C:\\Users\\LEEJUHWAN\\Downloads\\documents_2010_imgFixed.cmds\"  # 입력 CMDS 파일\n",
    "    output_cmds = r\"C:\\Users\\LEEJUHWAN\\Downloads\\documents_2010_imgFixed_timefixed.cmds\"  # 출력 CMDS 파일\n",
    "    \n",
    "    process_cmds(csv_file, input_cmds, output_cmds)\n",
    "    print('처리 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4e1f6b-fc3b-42e3-a11d-915a6f5736ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m input_cmds = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mLEEJUHWAN\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdocuments_2010_imgFixed.cmds\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 입력 CMDS 파일\u001b[39;00m\n\u001b[32m    121\u001b[39m output_cmds = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mLEEJUHWAN\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDownloads\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdocuments_2010_imgFixed_timefixed.cmds\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# 출력 CMDS 파일\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43mprocess_cmds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_cmds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_cmds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m처리 완료!\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mprocess_cmds\u001b[39m\u001b[34m(csv_file, input_cmds, output_cmds)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m처리 중... \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m건\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# JSON 파싱\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# sourceId에서 document_id 추출\u001b[39;00m\n\u001b[32m     59\u001b[39m source_id = data.get(\u001b[33m'\u001b[39m\u001b[33msourceId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     end = _w(s, end).end()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\Lib\\json\\decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    361\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# id 같은데 제목 다를경우 콘솔에 찍히게 수정\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# 상태 매핑 딕셔너리\n",
    "STATUS_MAP = {\n",
    "    '기안': 'DRAFT',\n",
    "    '승인': 'APPROVAL',\n",
    "    '합의': 'AGREEMENT'\n",
    "}\n",
    "\n",
    "def extract_document_id(source_id):\n",
    "    \"\"\"sourceId에서 document_id 추출 (예: doc_2985802_02 → 2985802)\"\"\"\n",
    "    match = re.search(r'doc_(\\d+)_', source_id)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def parse_approval_date(date_str):\n",
    "    \"\"\"날짜 문자열을 유닉스 타임스탬프 밀리초로 변환\"\"\"\n",
    "    dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(dt.timestamp() * 1000)\n",
    "\n",
    "def process_cmds(csv_file, input_cmds, output_cmds):\n",
    "    # CSV 파일 읽기\n",
    "    csv_data = {}\n",
    "    with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            doc_id = row['document_id']\n",
    "            if doc_id not in csv_data:\n",
    "                csv_data[doc_id] = []\n",
    "            csv_data[doc_id].append(row)\n",
    "    \n",
    "    # 불일치 리스트\n",
    "    mismatch_list = []\n",
    "    line_count = 0\n",
    "    \n",
    "    # CMDS 파일 처리\n",
    "    with open(input_cmds, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(output_cmds, 'w', encoding='utf-8') as f_out:\n",
    "        \n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            line_count += 1\n",
    "            \n",
    "            # 진행상황 표시 (1000건마다)\n",
    "            if line_count % 1000 == 0:\n",
    "                print(f'처리 중... {line_count}건')\n",
    "            \n",
    "            # JSON 파싱\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # sourceId에서 document_id 추출\n",
    "            source_id = data.get('sourceId', '')\n",
    "            doc_id = extract_document_id(source_id)\n",
    "            \n",
    "            if doc_id and doc_id in csv_data:\n",
    "                csv_rows = csv_data[doc_id]\n",
    "                \n",
    "                # 제목 비교 (CMDS의 title vs CSV의 post_title)\n",
    "                cmds_title = data.get('title', '')\n",
    "                csv_title = csv_rows[0]['post_title']\n",
    "                \n",
    "                if cmds_title != csv_title:\n",
    "                    # 제목 불일치 - 리스트에 추가하고 원본 그대로 출력\n",
    "                    mismatch_list.append({\n",
    "                        'doc_id': doc_id,\n",
    "                        'cmds_title': cmds_title,\n",
    "                        'csv_title': csv_title\n",
    "                    })\n",
    "                    output_line = json.dumps(data, ensure_ascii=False, separators=(',', ':'))\n",
    "                    f_out.write(output_line + '\\n')\n",
    "                    continue\n",
    "                \n",
    "                # 제목 일치 - activities 업데이트\n",
    "                for activity in data.get('activities', []):\n",
    "                    activity_type = activity.get('type', '')\n",
    "                    activity_name = activity.get('name', '')\n",
    "                    \n",
    "                    # CSV에서 매칭되는 행 찾기\n",
    "                    for csv_row in csv_rows:\n",
    "                        csv_status = STATUS_MAP.get(csv_row['status'], '')\n",
    "                        csv_approver = csv_row['approver']\n",
    "                        \n",
    "                        # type과 name이 모두 일치하는지 확인\n",
    "                        if (activity_type == csv_status and \n",
    "                            activity_name in csv_approver):\n",
    "                            \n",
    "                            # actionDate 업데이트\n",
    "                            approval_date = csv_row['approval_date']\n",
    "                            activity['actionDate'] = parse_approval_date(approval_date)\n",
    "                            break\n",
    "            \n",
    "            # JSON을 한 줄로 변환하여 출력\n",
    "            output_line = json.dumps(data, ensure_ascii=False, separators=(',', ':'))\n",
    "            f_out.write(output_line + '\\n')\n",
    "    \n",
    "    # 처리 완료 후 불일치 로그 출력\n",
    "    print(f'\\n총 처리: {line_count}건')\n",
    "    \n",
    "    if len(mismatch_list) > 0:\n",
    "        # 불일치가 있으면 항상 파일로 저장\n",
    "        with open('title_mismatch.log', 'w', encoding='utf-8') as log:\n",
    "            for item in mismatch_list:\n",
    "                log.write(f\"Doc ID: {item['doc_id']}\\n\")\n",
    "                log.write(f\"CMDS title: {item['cmds_title']}\\n\")\n",
    "                log.write(f\"CSV post_title: {item['csv_title']}\\n\\n\")\n",
    "        print(f'⚠️ 제목 불일치: {len(mismatch_list)}건 (title_mismatch.log 파일 확인)')\n",
    "    else:\n",
    "        print('✓ 모든 제목 일치')\n",
    "\n",
    "# 실행\n",
    "if __name__ == '__main__':\n",
    "    csv_file = r\"C:\\Users\\LEEJUHWAN\\Downloads\\crawling_approval_data_2010.csv\"  # CSV 파일 경로\n",
    "    input_cmds = r\"C:\\Users\\LEEJUHWAN\\Downloads\\documents_2010_imgFixed.cmds\"  # 입력 CMDS 파일\n",
    "    output_cmds = r\"C:\\Users\\LEEJUHWAN\\Downloads\\documents_2010_imgFixed_timefixed.cmds\"  # 출력 CMDS 파일\n",
    "    \n",
    "    process_cmds(csv_file, input_cmds, output_cmds)\n",
    "    print('처리 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee75c12-c70c-469a-9da5-d4e1f43cf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# 상태 매핑 딕셔너리\n",
    "STATUS_MAP = {\n",
    "    '기안': 'DRAFT',\n",
    "    '승인': 'APPROVAL',\n",
    "    '합의': 'AGREEMENT'\n",
    "}\n",
    "\n",
    "def extract_document_id(source_id):\n",
    "    \"\"\"sourceId에서 document_id 추출 (예: doc_2985802_02 → 2985802)\"\"\"\n",
    "    match = re.search(r'doc_(\\d+)_', source_id)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def parse_approval_date(date_str):\n",
    "    \"\"\"날짜 문자열을 유닉스 타임스탬프 밀리초로 변환\"\"\"\n",
    "    dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(dt.timestamp() * 1000)\n",
    "\n",
    "def process_cmds(csv_file, input_cmds, output_cmds):\n",
    "    # CSV 파일 읽기\n",
    "    csv_data = {}\n",
    "    with open(csv_file, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            doc_id = row['document_id']\n",
    "            if doc_id not in csv_data:\n",
    "                csv_data[doc_id] = []\n",
    "            csv_data[doc_id].append(row)\n",
    "    \n",
    "    # CMDS 파일 처리\n",
    "    with open(input_cmds, 'r', encoding='utf-8') as f_in, \\\n",
    "         open(output_cmds, 'w', encoding='utf-8') as f_out:\n",
    "        \n",
    "        for line in f_in:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # JSON 파싱\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # sourceId에서 document_id 추출\n",
    "            source_id = data.get('sourceId', '')\n",
    "            doc_id = extract_document_id(source_id)\n",
    "            \n",
    "            if doc_id and doc_id in csv_data:\n",
    "                csv_rows = csv_data[doc_id]\n",
    "                \n",
    "                # activities 업데이트\n",
    "                for activity in data.get('activities', []):\n",
    "                    activity_type = activity.get('type', '')\n",
    "                    activity_name = activity.get('name', '')\n",
    "                    \n",
    "                    # CSV에서 매칭되는 행 찾기\n",
    "                    for csv_row in csv_rows:\n",
    "                        csv_status = STATUS_MAP.get(csv_row['status'], '')\n",
    "                        csv_approver = csv_row['approver']\n",
    "                        \n",
    "                        # type과 name이 모두 일치하는지 확인\n",
    "                        if (activity_type == csv_status and \n",
    "                            activity_name in csv_approver):\n",
    "                            \n",
    "                            # actionDate 업데이트\n",
    "                            approval_date = csv_row['approval_date']\n",
    "                            activity['actionDate'] = parse_approval_date(approval_date)\n",
    "                            break\n",
    "            \n",
    "            # JSON을 한 줄로 변환하여 출력\n",
    "            output_line = json.dumps(data, ensure_ascii=False, separators=(',', ':'))\n",
    "            f_out.write(output_line + '\\n')\n",
    "\n",
    "# 실행\n",
    "if __name__ == '__main__':\n",
    "    csv_file = 'approval_data.csv'  # CSV 파일 경로\n",
    "    input_cmds = 'input.cmds'  # 입력 CMDS 파일\n",
    "    output_cmds = 'output.cmds'  # 출력 CMDS 파일\n",
    "    \n",
    "    process_cmds(csv_file, input_cmds, output_cmds)\n",
    "    print('처리 완료!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
