{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9cd056-97ee-4ca0-829b-63e9a0e6683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 840ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/840] 20100225_ì—°ì°¨íœ´ê°€(3_2) ì‹ ì²­í•©ë‹ˆë‹¤._2002163.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/840] 20100401_[ê¸°ìˆ ì§€ì›íŒ€ ê²©ë ¤ ì¸ì„¼í‹°ë¸Œ ì§€ê¸‰í’ˆì˜]_2002268.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/840] 20100517_ê°œì¸íœ´ê°€í’ˆì˜_2002367.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/840] 20100705_íŒŒì¼ì„œë²„ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­_2002467.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/840] 20100817_8ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ê¸°ìˆ ì§€ì›ë¶€ë¬¸_2002570.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/840] 20100929_ì¬ì§ì¦ëª…ì„œ ë°œê¸‰ìš”ì²­_2002666.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/840] 20101110_ëŒ€ì „ì§€ì‚¬ ê³µìš© í•˜ë“œë””ìŠ¤í¬ êµ¬ë§¤ ìš”ì²­_2002767.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/840] 20101221_12ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ì „ë¬¸ê°€Gr.(ê¹€ê·œì¼)_2002865.html\n",
      "ì²˜ë¦¬ ì¤‘... [840/840] 20101231_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (10ì›”,11ì›”,12ì›”)_2002907.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (840ê±´) ===\n",
      "  ì§„í–‰: 100/840 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/840 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/840 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/840 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/840 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/840 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/840 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/840 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 840/840 (ë§¤ì¹­: 840, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 840ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 840ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "#actionComment  ì¶”ì¶œ ê°œì„ \n",
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\n",
    "\"\"\"\n",
    " [ê¸°ëŠ¥]\n",
    " HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë¥¼ ì¬ì¶”ì¶œí•˜ì—¬\n",
    " DB documents í…Œì´ë¸”ì˜ í•´ë‹¹ ì»¬ëŸ¼ë§Œ UPDATE\n",
    " (í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€)\n",
    "\n",
    " [ì¶”ì¶œ ëŒ€ìƒ]\n",
    " - drafter: ê¸°ì•ˆì ì •ë³´ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì\" í–‰ì—ì„œ)\n",
    " - createdAt: ê¸°ì•ˆì¼ì‹œ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì¼\" í–‰ì—ì„œ, KSTâ†’Unix ms)\n",
    " - activities: ê²°ì¬ í™œë™ ë¡œê·¸ (bg02 divì—ì„œ)\n",
    "   - actionComment: user_spansì—ì„œ ì¶”ê°€ ì¶”ì¶œ\n",
    "\n",
    " [CSV ì¡°ì§ë„ ë§¤ì¹­]\n",
    " - í˜„ì§ì: CSVì—ì„œ positionName, deptName, emailId, deptCode ë§¤ì¹­\n",
    " - í‡´ì‚¬ì: emailIdë¥¼ 'master'ë¡œ ì„¤ì •, ë‚˜ë¨¸ì§€ ê³µë€\n",
    "\n",
    " [activities ì¶”ì¶œ ë¡œì§]\n",
    " 1. bg02 div ë‚´ ul > liì—ì„œ ì´ë¦„, íƒ€ì…, ë‚ ì§œ ì¶”ì¶œ\n",
    " 2. íƒ€ì… ê²°ì •: ê¸°ì•ˆâ†’DRAFT, í•©ì˜â†’AGREEMENT, ê·¸ì™¸â†’APPROVAL\n",
    " 3. ë‚ ì§œ: MM/DD í˜•ì‹ â†’ createdAt ì—°ë„ + KST ë³€í™˜\n",
    " 4. actionComment: user_spans ìˆœíšŒí•˜ë©° ë‹¤ìŒ divì—ì„œ ì˜ê²¬ ì¶”ì¶œ\n",
    "\n",
    " [ì‹œê°„ëŒ€ ì²˜ë¦¬]\n",
    " - ëª¨ë“  ë‚ ì§œë¥¼ KST(Asia/Seoul)ë¡œ ì²˜ë¦¬ í›„ Unix timestamp ë³€í™˜\n",
    "\n",
    " [ë™ì‘ ìˆœì„œ]\n",
    " 1. CSV ì¡°ì§ë„ ë¡œë“œ\n",
    " 2. HTML í´ë”ì—ì„œ íŒŒì¼ ìˆœíšŒ\n",
    " 3. ê° HTMLì—ì„œ drafter, createdAt, activities ì¶”ì¶œ\n",
    " 4. JSON íŒŒì¼ë¡œ ì €ì¥\n",
    " 5. DB UPDATE (source_id + end_yearë¡œ ë§¤ì¹­)\n",
    "\n",
    " [ì¶œë ¥]\n",
    " - JSON íŒŒì¼: update_drafter_activities.json\n",
    " - MariaDB: documents í…Œì´ë¸”ì˜ drafter_*, created_at, activities ì»¬ëŸ¼ UPDATE\n",
    "\n",
    " [ì„¤ì • (#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)]\n",
    " - base_path: HTML í´ë” ê²½ë¡œ\n",
    " - end_year: ëŒ€ìƒ ì—°ë„ (WHERE ì¡°ê±´)\n",
    " - csv_file: ì¸ì‚¬ì •ë³´ CSV íŒŒì¼\n",
    " - db_config: DB ì ‘ì† ì •ë³´\n",
    "\n",
    " [ì˜ì¡´ì„±]\n",
    " - beautifulsoup4\n",
    " - pymysql\n",
    " - pandas\n",
    " - pytz\n",
    " -> pip install beautifulsoup4 pymysql pandas pytz\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) - ê°œì„ ë¨ ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_span ì´í›„ ë‹¤ìŒ user_span ì „ê¹Œì§€ì˜ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    \n",
    "                    # next_siblingsë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ íƒìƒ‰\n",
    "                    for sibling in user_span.next_siblings:\n",
    "                        # ë‹¤ìŒ user_spanì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨\n",
    "                        if hasattr(sibling, 'name'):\n",
    "                            if sibling.name == 'span' and 'user' in sibling.get('class', []):\n",
    "                                break\n",
    "                            # divë¥¼ ì°¾ìœ¼ë©´ ì €ì¥í•˜ê³  ì¤‘ë‹¨\n",
    "                            if sibling.name == 'div':\n",
    "                                action_comment = sibling.get_text(strip=True)\n",
    "                                break\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2010-01-01~2010-12-31\\html'\n",
    "    end_year = 2010\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b6a8c8-db98-4d35-bffd-1c5ebacde3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 840ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/840] 20100225_ì—°ì°¨íœ´ê°€(3_2) ì‹ ì²­í•©ë‹ˆë‹¤._2002163.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/840] 20100401_[ê¸°ìˆ ì§€ì›íŒ€ ê²©ë ¤ ì¸ì„¼í‹°ë¸Œ ì§€ê¸‰í’ˆì˜]_2002268.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/840] 20100517_ê°œì¸íœ´ê°€í’ˆì˜_2002367.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/840] 20100705_íŒŒì¼ì„œë²„ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­_2002467.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/840] 20100817_8ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ê¸°ìˆ ì§€ì›ë¶€ë¬¸_2002570.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/840] 20100929_ì¬ì§ì¦ëª…ì„œ ë°œê¸‰ìš”ì²­_2002666.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/840] 20101110_ëŒ€ì „ì§€ì‚¬ ê³µìš© í•˜ë“œë””ìŠ¤í¬ êµ¬ë§¤ ìš”ì²­_2002767.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/840] 20101221_12ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ì „ë¬¸ê°€Gr.(ê¹€ê·œì¼)_2002865.html\n",
      "ì²˜ë¦¬ ì¤‘... [840/840] 20101231_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (10ì›”,11ì›”,12ì›”)_2002907.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (840ê±´) ===\n",
      "  ì§„í–‰: 100/840 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/840 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/840 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/840 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/840 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/840 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/840 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/840 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 840/840 (ë§¤ì¹­: 840, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 840ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 840ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz  # â† ì¶”ê°€\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')  # â† ì¶”ê°€: í•œêµ­ ì‹œê°„ëŒ€\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        # naive datetime ìƒì„± í›„ KSTë¡œ ëª…ì‹œ\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬ ì¶”ê°€\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_spanì˜ ë¶€ëª¨(td)ì—ì„œ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    parent = user_span.parent\n",
    "                    if parent:\n",
    "                        comment_div = parent.find('div')\n",
    "                        if comment_div:\n",
    "                            action_comment = comment_div.get_text(strip=True)\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS  # â† ì¶”ê°€!\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜ (ë³€ê²½ ì—¬ë¶€ ë¬´ê´€)\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2010-01-01~2010-12-31\\html'\n",
    "    end_year = 2010\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
