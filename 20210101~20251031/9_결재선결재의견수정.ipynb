{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9cd056-97ee-4ca0-829b-63e9a0e6683b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 8175ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/8175] 20210204_ëª…í•¨ë°œê¸‰ì„ ìš”ì²­í•©ë‹ˆë‹¤._15362351.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/8175] 20210323_ì—°ì°¨ í’ˆì˜ì„œ_15618962.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/8175] 20210504_ì—°ì°¨íœ´ê°€ ì‹ ì²­_15873929.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/8175] 20210611_2021-06-14(ì›”) íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤ - 1ì¼_16094756.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/8175] 20210707_ì˜¤ì „ ë°˜ì°¨ ì‹ ì²­í•©ë‹ˆë‹¤._16246418.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/8175] 20210728_ê¹€ìƒìš± íœ´ê°€ ì‚¬ìš© ì‹ ì²­ì„œ ì…ë‹ˆë‹¤._16375259.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/8175] 20210820_08-16 NHN NB, Monitor x 23_16509307.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/8175] 20210914_2021ë…„ 9ì›” 16ì¼(ëª©) ì—°ì°¨ íœ´ê°€(ë°±ì‹ ) ì‹ ì²­í•©ë‹ˆë‹¤_16657522.html\n",
      "ì²˜ë¦¬ ì¤‘... [900/8175] 20211008_[êµ¬ë§¤_ì™¸ì£¼ì¸ë ¥] (ì£¼)ì—˜ì§€í™”í•™_[R&amp;D] LGí™”í•™ ì„œë¹„ìŠ¤ì„¤ëª…ì„œ_íŠ¹í—ˆì‹œìŠ¤í…œ_SMìš´ì˜ - ê¹€ê´‘ë¦¼(í”„ë¦¬ëœì„œ)_16782949.html\n",
      "ì²˜ë¦¬ ì¤‘... [1000/8175] 20211028_10ì›” ê¸°íƒ€ ê²½ë¹„ ì‹ ì²­í•©ë‹ˆë‹¤_16906849.html\n",
      "ì²˜ë¦¬ ì¤‘... [1100/8175] 20211116_11-18 MHNco NB x 1_17024023.html\n",
      "ì²˜ë¦¬ ì¤‘... [1200/8175] 20211210_(ê¸°ëŠ¥ê°œì„ ) OCI íŠ¹í—ˆê´€ë¦¬ì‹œìŠ¤í…œ ì¡°ì‚¬ë¶„ì„ ë° ERP ê¸°ëŠ¥ê°œì„  ê³„ì•½í’ˆì˜_17187276.html\n",
      "ì²˜ë¦¬ ì¤‘... [1300/8175] 20211224_íœ´ê°€ ì‚¬ìš© ì‹ ì²­ì„œ_ì´ì˜í™˜ ì„ ì„_17276280.html\n",
      "ì²˜ë¦¬ ì¤‘... [1400/8175] 20220113_íœ´ê°€ ì‚¬ìš© ì‹ ì²­í•©ë‹ˆë‹¤._17403800.html\n",
      "ì²˜ë¦¬ ì¤‘... [1500/8175] 20220207_ê²½ë¹„ì‹ ì²­_17526024.html\n",
      "ì²˜ë¦¬ ì¤‘... [1600/8175] 20220225_02-13 ë‚˜ì´ìŠ¤ kit x 16_17654234.html\n",
      "ì²˜ë¦¬ ì¤‘... [1700/8175] 20220330_03-22 í•œêµ­ì‹ ìš© Monitor x 3_17941716.html\n",
      "ì²˜ë¦¬ ì¤‘... [1800/8175] 20220425_ëŒ€ì „ ì›ìë ¥ì—°êµ¬ì› ì¶œì¥ í’ˆì˜ì„œ ì…ë‹ˆë‹¤_18114640.html\n",
      "ì²˜ë¦¬ ì¤‘... [1900/8175] 20220512_[ëŒ€ê¸ˆê²°ì œ] ITO_5ì›” ì™¸ì£¼ìš©ì—­ë¹„ ëŒ€ê¸ˆ ê²°ì œì˜ ê±´ (05_15)_18229306.html\n",
      "ì²˜ë¦¬ ì¤‘... [2000/8175] 20220531_05-38 NHN NB x 4_18351753.html\n",
      "ì²˜ë¦¬ ì¤‘... [2100/8175] 20220620_22_07_13(ìˆ˜) ì—°ì°¨íœ´ê°€ ì‹ ì²­ë“œë¦½ë‹ˆë‹¤._18473049.html\n",
      "ì²˜ë¦¬ ì¤‘... [2200/8175] 20220708_&quot;ì°¨ì„¸ëŒ€ìœµí•©ê¸°ìˆ ì—°êµ¬ì›_í†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ êµ¬ì¶•&quot; ì™¸ì£¼ì¸ë ¥ ê³„ì•½í’ˆì˜(ì£¼ë³‘êµ­_ê³ ê¸‰)_220708_18606420.html\n",
      "ì²˜ë¦¬ ì¤‘... [2300/8175] 20220720_7_22, 7_25 í•˜ê³„ íœ´ê°€ ì‹ ì²­ë“œë¦½ë‹ˆë‹¤._18677393.html\n",
      "ì²˜ë¦¬ ì¤‘... [2400/8175] 20220804_ì˜¤ì „ ë°˜ì°¨ ì‹ ì²­í•©ë‹ˆë‹¤_18770649.html\n",
      "ì²˜ë¦¬ ì¤‘... [2500/8175] 20220825_ë°˜ì°¨ ê²°ì¬ìš”ì²­_18900851.html\n",
      "ì²˜ë¦¬ ì¤‘... [2600/8175] 20220916_íœ´ê°€ì‹ ì²­ 09_21_19036686.html\n",
      "ì²˜ë¦¬ ì¤‘... [2700/8175] 20221012_KINPA 2022 í–‰ì‚¬ìš© ë°©ë¬¸ì‚¬ì€í’ˆ êµ¬ë§¤ ë¹„ìš© ì‹ ì²­ (10_12)_19198962.html\n",
      "ì²˜ë¦¬ ì¤‘... [2800/8175] 20221103_ë°˜ì°¨ ê²°ì¬ìš”ì²­_19346464.html\n",
      "ì²˜ë¦¬ ì¤‘... [2900/8175] 20221123_[ëŒ€ê¸ˆê²°ì œ] ë¦¬ëª¨íŠ¸ì½œ(Remote Call) ì„œë¹„ìŠ¤ ì‚¬ìš© ê°±ì‹  êµ¬ë§¤_ì•Œì„œí¬íŠ¸_19481509.html\n",
      "ì²˜ë¦¬ ì¤‘... [3000/8175] 20221208_ë°˜ì°¨ ì‚¬ìš© ì‹ ì²­_19585662.html\n",
      "ì²˜ë¦¬ ì¤‘... [3100/8175] 20221222_[ëŒ€ê¸ˆê²°ì œ]í•œêµ­ì „ê¸°ì—°êµ¬ì› ì§€ì‹ì¬ì‚°í†µí•©ê´€ë¦¬ì‹œìŠ¤í…œ êµ¬ì¶• ëŒ€ê¸ˆì§€ê¸‰ì˜ ê±´_(ì£¼)TIS_19687360.html\n",
      "ì²˜ë¦¬ ì¤‘... [3200/8175] 20230113_01-15 NHN Monitor x 12_19833418.html\n",
      "ì²˜ë¦¬ ì¤‘... [3300/8175] 20230209_2ì›” 9ì¼ íœ´ê°€ ì‹ ì²­_19994078.html\n",
      "ì²˜ë¦¬ ì¤‘... [3400/8175] 20230307_ì—°ì°¨íœ´ê°€ ì‹ ì²­_20158070.html\n",
      "ì²˜ë¦¬ ì¤‘... [3500/8175] 20230330_[í•œêµ­ì¡°ì„ í•´ì–‘]ìˆ™ë°•ë¹„ ê²°ì œìš”ì²­ê±´ì…ë‹ˆë‹¤._20318248.html\n",
      "ì²˜ë¦¬ ì¤‘... [3600/8175] 20230425_í•œêµ­ì—°êµ¬ì¬ë‹¨ ì—°êµ¬ì§€ì› í†µí•©DB ì‹œìŠ¤í…œêµ¬ì¶• ë§¤ì¶œ í’ˆì˜ ê±´_20490755.html\n",
      "ì²˜ë¦¬ ì¤‘... [3700/8175] 20230523_05-15 ë°±ì‚°ì‹œìŠ¤í…œ PC, Monitor x 80_20661357.html\n",
      "ì²˜ë¦¬ ì¤‘... [3800/8175] 20230621_06-10 NHN Monitor x 16_20842708.html\n",
      "ì²˜ë¦¬ ì¤‘... [3900/8175] 20230713_ëŒ€ê¸ˆê²°ì œ_ì—°êµ¬í™œë™ë¹„_(ì£¼)ë ˆë“œìœ—_ì „ìì—°êµ¬ë…¸íŠ¸ êµ¬ë…ë£Œ_ì‚°ì—…ë¶€ ATC ê°œë°œ ê³¼ì œ_20995786.html\n",
      "ì²˜ë¦¬ ì¤‘... [4000/8175] 20230807_8ì›” 14ì¼ íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤._21150983.html\n",
      "ì²˜ë¦¬ ì¤‘... [4100/8175] 20230831_[ëŒ€ì „ ì§€ì‚¬] ê¹€ í›ˆí¬ ì´ì‚¬ ë°˜ì°¨ë¥¼ ì‹ ì²­ í•©ë‹ˆë‹¤._21297207.html\n",
      "ì²˜ë¦¬ ì¤‘... [4200/8175] 20230925_ì—°ì°¨íœ´ê°€ ì‹ ì²­_21465011.html\n",
      "ì²˜ë¦¬ ì¤‘... [4300/8175] 20231026_ìœ¤ì˜í˜„ ê²½ë¹„ì‹ ì²­í•©ë‹ˆë‹¤_21643287.html\n",
      "ì²˜ë¦¬ ì¤‘... [4400/8175] 20231120_[S_WíŒ€] ê¹€í•˜ëŠ˜ ì‚¬ì› íœ´ê°€ ì‚¬ìš© ì‹ ì²­ì„œì…ë‹ˆë‹¤._21804616.html\n",
      "ì²˜ë¦¬ ì¤‘... [4500/8175] 20231211_ê°œì¸ íœ´ê°€ ì‚¬ìš© ì‹ ì²­(2022.12.18(ì›”) ì—°ì°¨)_21949988.html\n",
      "ì²˜ë¦¬ ì¤‘... [4600/8175] 20240102_íœ´ê°€ ì‚¬ìš©ì‹ ì²­_22082764.html\n",
      "ì²˜ë¦¬ ì¤‘... [4700/8175] 20240129_24.01.30 - ìœ ë¯¼ê²½ ì‚¬ì› ë°˜ì°¨ ì‹ ì²­ì„œ_22266378.html\n",
      "ì²˜ë¦¬ ì¤‘... [4800/8175] 20240220_ì˜ˆë¹„êµ° í›ˆë ¨ ì‹ ì²­ í’ˆì˜ì„œ_22400124.html\n",
      "ì²˜ë¦¬ ì¤‘... [4900/8175] 20240314_20230318_ì‚¬ì›_ê°•í˜„ íœ´ê°€ì‹ ì²­í•©ë‹ˆë‹¤_22563960.html\n",
      "ì²˜ë¦¬ ì¤‘... [5000/8175] 20240401_íœ´ê°€ ì‚¬ìš©ì‹ ì²­_22674012.html\n",
      "ì²˜ë¦¬ ì¤‘... [5100/8175] 20240424_íœ´ê°€ ì‹ ì²­ì„œ(4_29ì¼)_22831840.html\n",
      "ì²˜ë¦¬ ì¤‘... [5200/8175] 20240517_05-09 DCT ìœ ì§€ë³´ìˆ˜ x 1_22976134.html\n",
      "ì²˜ë¦¬ ì¤‘... [5300/8175] 20240607_ì—°ì°¨ ì‚¬ìš© í’ˆì˜ - ì‹ ì„±í˜¸_23112221.html\n",
      "ì²˜ë¦¬ ì¤‘... [5400/8175] 20240701_2024-01~06ì›” HDí˜„ëŒ€ ì‹¸ì´íŠ¸ì†”ë£¨ì…˜ ì¶œì¥ë¹„ ì‹ ì²­ì˜ ê±´_23262611.html\n",
      "ì²˜ë¦¬ ì¤‘... [5500/8175] 20240716_2024-07-22 ê¹€ì§€ì—° íœ´ê°€ ì‹ ì²­í•©ë‹ˆë‹¤ - 1ì¼_23371629.html\n",
      "ì²˜ë¦¬ ì¤‘... [5600/8175] 20240730_7ì›” ê¸°íƒ€ ê²½ë¹„ ì‹ ì²­í•©ë‹ˆë‹¤_23464832.html\n",
      "ì²˜ë¦¬ ì¤‘... [5700/8175] 20240819_[ATC+ê³¼ì œ]ê²°ì œí’ˆì˜_ì—°êµ¬ì¬ë£Œë¹„_íŠ¹í—ˆ ë°ì´í„° êµ¬ì…ë¹„_KIPRIS_23586050.html\n",
      "ì²˜ë¦¬ ì¤‘... [5800/8175] 20240910_íœ´ê°€ë¥¼ ì‹ ì²­í•©ë‹ˆë‹¤._23744049.html\n",
      "ì²˜ë¦¬ ì¤‘... [5900/8175] 20241002_íœ´ê°€ ì‚¬ìš© ì‹ ì²­ì„œ_23855991.html\n",
      "ì²˜ë¦¬ ì¤‘... [6000/8175] 20241024_íœ´ê°€ë¥¼ ì‹ ì²­í•©ë‹ˆë‹¤._23997567.html\n",
      "ì²˜ë¦¬ ì¤‘... [6100/8175] 20241113_11-04 NHN WS, Kit x 19_24137629.html\n",
      "ì²˜ë¦¬ ì¤‘... [6200/8175] 20241202_2024ë…„ë„ ì—°ì°¨íœ´ê°€(2024ë…„12ì›”05ì¼~06ì¼, 2ì¼) ì‹ ì²­í•©ë‹ˆë‹¤. AI &amp; BigDATA ì´ì‹œìš° ì±…ì„_24260435.html\n",
      "ì²˜ë¦¬ ì¤‘... [6300/8175] 20241217_ì—°ì°¨íœ´ê°€í’ˆì˜_24373069.html\n",
      "ì²˜ë¦¬ ì¤‘... [6400/8175] 20241231_12ì›” êµí†µë¹„_24460629.html\n",
      "ì²˜ë¦¬ ì¤‘... [6500/8175] 20250117_2025-01-20 ê¹€ì°¬ì§„_íœ´ê°€(ë°˜ì°¨)_24580291.html\n",
      "ì²˜ë¦¬ ì¤‘... [6600/8175] 20250206_ì—°ì°¨ íœ´ê°€ ì‹ ì²­ (2_7 1ì¼)_24688533.html\n",
      "ì²˜ë¦¬ ì¤‘... [6700/8175] 20250224_íœ´ê°€ë¥¼ ì‹ ì²­í•©ë‹ˆë‹¤._24798000.html\n",
      "ì²˜ë¦¬ ì¤‘... [6800/8175] 20250313_í•œêµ­ì—°êµ¬ì¬ë‹¨ í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ ì „í™˜ êµ¬ë§¤ ê³„ì•½ í’ˆì˜(ì™¸ì£¼ì¸ê±´ë¹„) ì˜ ê±´_24928218.html\n",
      "ì²˜ë¦¬ ì¤‘... [6900/8175] 20250327_03-20 NHN Monitor x 20_25018789.html\n",
      "ì²˜ë¦¬ ì¤‘... [7000/8175] 20250414_ì˜¤ì „ë°˜ì°¨ì‚¬ìš©í’ˆì˜_25145536.html\n",
      "ì²˜ë¦¬ ì¤‘... [7100/8175] 20250428_4ì›” êµí†µë¹„_25239324.html\n",
      "ì²˜ë¦¬ ì¤‘... [7200/8175] 20250519_20250523_ì‚¬ì› ê¹€ë¯¼ì • ê°œì¸íœ´ê°€ ì‹ ì²­_25369122.html\n",
      "ì²˜ë¦¬ ì¤‘... [7300/8175] 20250604_25.06.13 - ìœ ë¯¼ê²½ ì‚¬ì› ì—°ì°¨ ì‹ ì²­ì„œ_25467901.html\n",
      "ì²˜ë¦¬ ì¤‘... [7400/8175] 20250625_06-15 ì´ëœë“œ Monitor x 6_25603146.html\n",
      "ì²˜ë¦¬ ì¤‘... [7500/8175] 20250710_[ëŒ€ê¸ˆê²°ì œ] ITO_7ì›” ì™¸ì£¼ìš©ì—­ë¹„ ëŒ€ê¸ˆ ê²°ì œì˜ ê±´ (07_15)_25714542.html\n",
      "ì²˜ë¦¬ ì¤‘... [7600/8175] 20250724_ì™•ì •í˜„ í‡´ì§ í’ˆì˜ì„œì…ë‹ˆë‹¤._25810767.html\n",
      "ì²˜ë¦¬ ì¤‘... [7700/8175] 20250808_ì—°ì°¨ ì‚¬ìš©_25909047.html\n",
      "ì²˜ë¦¬ ì¤‘... [7800/8175] 20250825_[ëŒ€ì „ ì§€ì‚¬] ê¹€ í›ˆí¬ ì´ì‚¬ íœ´ê°€ë¥¼ ì‹ ì²­ í•©ë‹ˆë‹¤.  - ê¹€ í›ˆí¬ ë“œë¦¼_25993972.html\n",
      "ì²˜ë¦¬ ì¤‘... [7900/8175] 20250911_íœ´ê°€ ì‚¬ìš© ì‹ ì²­(ë°˜ì°¨)_26126644.html\n",
      "ì²˜ë¦¬ ì¤‘... [8000/8175] 20250926_ìˆ™ì†Œ_ê°€ì‚°ë²„í”Œë¦­ 1401í˜¸ ê³„ì•½ í’ˆì˜_26222545.html\n",
      "ì²˜ë¦¬ ì¤‘... [8100/8175] 20251017_10-02 NHN Monitor x 50_26329187.html\n",
      "ì²˜ë¦¬ ì¤‘... [8175/8175] 20251031_íœ´ê°€ ì‚¬ìš© ì‹ ì²­_26418663.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (8175ê±´) ===\n",
      "  ì§„í–‰: 100/8175 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/8175 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/8175 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/8175 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/8175 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/8175 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/8175 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/8175 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 900/8175 (ë§¤ì¹­: 900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1000/8175 (ë§¤ì¹­: 1000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1100/8175 (ë§¤ì¹­: 1100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1200/8175 (ë§¤ì¹­: 1200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1300/8175 (ë§¤ì¹­: 1300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1400/8175 (ë§¤ì¹­: 1400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1500/8175 (ë§¤ì¹­: 1500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1600/8175 (ë§¤ì¹­: 1600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1700/8175 (ë§¤ì¹­: 1700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1800/8175 (ë§¤ì¹­: 1800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 1900/8175 (ë§¤ì¹­: 1900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2000/8175 (ë§¤ì¹­: 2000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2100/8175 (ë§¤ì¹­: 2100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2200/8175 (ë§¤ì¹­: 2200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2300/8175 (ë§¤ì¹­: 2300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2400/8175 (ë§¤ì¹­: 2400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2500/8175 (ë§¤ì¹­: 2500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2600/8175 (ë§¤ì¹­: 2600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2700/8175 (ë§¤ì¹­: 2700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2800/8175 (ë§¤ì¹­: 2800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 2900/8175 (ë§¤ì¹­: 2900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3000/8175 (ë§¤ì¹­: 3000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3100/8175 (ë§¤ì¹­: 3100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3200/8175 (ë§¤ì¹­: 3200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3300/8175 (ë§¤ì¹­: 3300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3400/8175 (ë§¤ì¹­: 3400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3500/8175 (ë§¤ì¹­: 3500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3600/8175 (ë§¤ì¹­: 3600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3700/8175 (ë§¤ì¹­: 3700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3800/8175 (ë§¤ì¹­: 3800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 3900/8175 (ë§¤ì¹­: 3900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4000/8175 (ë§¤ì¹­: 4000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4100/8175 (ë§¤ì¹­: 4100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4200/8175 (ë§¤ì¹­: 4200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4300/8175 (ë§¤ì¹­: 4300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4400/8175 (ë§¤ì¹­: 4400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4500/8175 (ë§¤ì¹­: 4500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4600/8175 (ë§¤ì¹­: 4600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4700/8175 (ë§¤ì¹­: 4700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4800/8175 (ë§¤ì¹­: 4800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 4900/8175 (ë§¤ì¹­: 4900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5000/8175 (ë§¤ì¹­: 5000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5100/8175 (ë§¤ì¹­: 5100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5200/8175 (ë§¤ì¹­: 5200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5300/8175 (ë§¤ì¹­: 5300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5400/8175 (ë§¤ì¹­: 5400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5500/8175 (ë§¤ì¹­: 5500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5600/8175 (ë§¤ì¹­: 5600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5700/8175 (ë§¤ì¹­: 5700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5800/8175 (ë§¤ì¹­: 5800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 5900/8175 (ë§¤ì¹­: 5900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6000/8175 (ë§¤ì¹­: 6000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6100/8175 (ë§¤ì¹­: 6100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6200/8175 (ë§¤ì¹­: 6200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6300/8175 (ë§¤ì¹­: 6300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6400/8175 (ë§¤ì¹­: 6400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6500/8175 (ë§¤ì¹­: 6500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6600/8175 (ë§¤ì¹­: 6600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6700/8175 (ë§¤ì¹­: 6700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6800/8175 (ë§¤ì¹­: 6800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 6900/8175 (ë§¤ì¹­: 6900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7000/8175 (ë§¤ì¹­: 7000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7100/8175 (ë§¤ì¹­: 7100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7200/8175 (ë§¤ì¹­: 7200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7300/8175 (ë§¤ì¹­: 7300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7400/8175 (ë§¤ì¹­: 7400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7500/8175 (ë§¤ì¹­: 7500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7600/8175 (ë§¤ì¹­: 7600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7700/8175 (ë§¤ì¹­: 7700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7800/8175 (ë§¤ì¹­: 7800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 7900/8175 (ë§¤ì¹­: 7900, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 8000/8175 (ë§¤ì¹­: 8000, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 8100/8175 (ë§¤ì¹­: 8100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 8175/8175 (ë§¤ì¹­: 8175, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 8175ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 8175ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "#actionComment  ì¶”ì¶œ ê°œì„ \n",
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\"\"\"\n",
    " [ê¸°ëŠ¥]\n",
    " HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë¥¼ ì¬ì¶”ì¶œí•˜ì—¬\n",
    " DB documents í…Œì´ë¸”ì˜ í•´ë‹¹ ì»¬ëŸ¼ë§Œ UPDATE\n",
    " (í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€)\n",
    "\n",
    " [ì¶”ì¶œ ëŒ€ìƒ]\n",
    " - drafter: ê¸°ì•ˆì ì •ë³´ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì\" í–‰ì—ì„œ)\n",
    " - createdAt: ê¸°ì•ˆì¼ì‹œ (í…Œì´ë¸”ì˜ \"ê¸°ì•ˆì¼\" í–‰ì—ì„œ, KSTâ†’Unix ms)\n",
    " - activities: ê²°ì¬ í™œë™ ë¡œê·¸ (bg02 divì—ì„œ)\n",
    "   - actionComment: user_spansì—ì„œ ì¶”ê°€ ì¶”ì¶œ\n",
    "\n",
    " [CSV ì¡°ì§ë„ ë§¤ì¹­]\n",
    " - í˜„ì§ì: CSVì—ì„œ positionName, deptName, emailId, deptCode ë§¤ì¹­\n",
    " - í‡´ì‚¬ì: emailIdë¥¼ 'master'ë¡œ ì„¤ì •, ë‚˜ë¨¸ì§€ ê³µë€\n",
    "\n",
    " [activities ì¶”ì¶œ ë¡œì§]\n",
    " 1. bg02 div ë‚´ ul > liì—ì„œ ì´ë¦„, íƒ€ì…, ë‚ ì§œ ì¶”ì¶œ\n",
    " 2. íƒ€ì… ê²°ì •: ê¸°ì•ˆâ†’DRAFT, í•©ì˜â†’AGREEMENT, ê·¸ì™¸â†’APPROVAL\n",
    " 3. ë‚ ì§œ: MM/DD í˜•ì‹ â†’ createdAt ì—°ë„ + KST ë³€í™˜\n",
    " 4. actionComment: user_spans ìˆœíšŒí•˜ë©° ë‹¤ìŒ divì—ì„œ ì˜ê²¬ ì¶”ì¶œ\n",
    "\n",
    " [ì‹œê°„ëŒ€ ì²˜ë¦¬]\n",
    " - ëª¨ë“  ë‚ ì§œë¥¼ KST(Asia/Seoul)ë¡œ ì²˜ë¦¬ í›„ Unix timestamp ë³€í™˜\n",
    "\n",
    " [ë™ì‘ ìˆœì„œ]\n",
    " 1. CSV ì¡°ì§ë„ ë¡œë“œ\n",
    " 2. HTML í´ë”ì—ì„œ íŒŒì¼ ìˆœíšŒ\n",
    " 3. ê° HTMLì—ì„œ drafter, createdAt, activities ì¶”ì¶œ\n",
    " 4. JSON íŒŒì¼ë¡œ ì €ì¥\n",
    " 5. DB UPDATE (source_id + end_yearë¡œ ë§¤ì¹­)\n",
    "\n",
    " [ì¶œë ¥]\n",
    " - JSON íŒŒì¼: update_drafter_activities.json\n",
    " - MariaDB: documents í…Œì´ë¸”ì˜ drafter_*, created_at, activities ì»¬ëŸ¼ UPDATE\n",
    "\n",
    " [ì„¤ì • (#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)]\n",
    " - base_path: HTML í´ë” ê²½ë¡œ\n",
    " - end_year: ëŒ€ìƒ ì—°ë„ (WHERE ì¡°ê±´)\n",
    " - csv_file: ì¸ì‚¬ì •ë³´ CSV íŒŒì¼\n",
    " - db_config: DB ì ‘ì† ì •ë³´\n",
    "\n",
    " [ì˜ì¡´ì„±]\n",
    " - beautifulsoup4\n",
    " - pymysql\n",
    " - pandas\n",
    " - pytz\n",
    " -> pip install beautifulsoup4 pymysql pandas pytz\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) - ê°œì„ ë¨ ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_span ì´í›„ ë‹¤ìŒ user_span ì „ê¹Œì§€ì˜ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    \n",
    "                    # next_siblingsë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì°¨ íƒìƒ‰\n",
    "                    for sibling in user_span.next_siblings:\n",
    "                        # ë‹¤ìŒ user_spanì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨\n",
    "                        if hasattr(sibling, 'name'):\n",
    "                            if sibling.name == 'span' and 'user' in sibling.get('class', []):\n",
    "                                break\n",
    "                            # divë¥¼ ì°¾ìœ¼ë©´ ì €ì¥í•˜ê³  ì¤‘ë‹¨\n",
    "                            if sibling.name == 'div':\n",
    "                                action_comment = sibling.get_text(strip=True)\n",
    "                                break\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "#ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2021-01-01~2025-10-31\\html'\n",
    "    end_year = 2025\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b6a8c8-db98-4d35-bffd-1c5ebacde3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... (ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv)\n",
      "âœ… ì´ 156ëª… ë¡œë“œ\n",
      "\n",
      "HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\n",
      "ì´ 840ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì²˜ë¦¬ ì¤‘... [100/840] 20100225_ì—°ì°¨íœ´ê°€(3_2) ì‹ ì²­í•©ë‹ˆë‹¤._2002163.html\n",
      "ì²˜ë¦¬ ì¤‘... [200/840] 20100401_[ê¸°ìˆ ì§€ì›íŒ€ ê²©ë ¤ ì¸ì„¼í‹°ë¸Œ ì§€ê¸‰í’ˆì˜]_2002268.html\n",
      "ì²˜ë¦¬ ì¤‘... [300/840] 20100517_ê°œì¸íœ´ê°€í’ˆì˜_2002367.html\n",
      "ì²˜ë¦¬ ì¤‘... [400/840] 20100705_íŒŒì¼ì„œë²„ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­_2002467.html\n",
      "ì²˜ë¦¬ ì¤‘... [500/840] 20100817_8ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ê¸°ìˆ ì§€ì›ë¶€ë¬¸_2002570.html\n",
      "ì²˜ë¦¬ ì¤‘... [600/840] 20100929_ì¬ì§ì¦ëª…ì„œ ë°œê¸‰ìš”ì²­_2002666.html\n",
      "ì²˜ë¦¬ ì¤‘... [700/840] 20101110_ëŒ€ì „ì§€ì‚¬ ê³µìš© í•˜ë“œë””ìŠ¤í¬ êµ¬ë§¤ ìš”ì²­_2002767.html\n",
      "ì²˜ë¦¬ ì¤‘... [800/840] 20101221_12ì›” ì•„ì›ƒì†Œì‹± ì¸ê±´ë¹„ ì§€ê¸‰ í’ˆì˜-ì „ë¬¸ê°€Gr.(ê¹€ê·œì¼)_2002865.html\n",
      "ì²˜ë¦¬ ì¤‘... [840/840] 20101231_ë²•ì¸ì¹´ë“œ ì‚¬ìš©ë‚´ì—­ ì •ì‚° ë³´ê³ (10ì›”,11ì›”,12ì›”)_2002907.html\n",
      "JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: update_drafter_activities.json\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DB ì—°ê²° ì‹œì‘ ===\n",
      "Host: localhost, Database: any_approval\n",
      "âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\n",
      "\n",
      "=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ (840ê±´) ===\n",
      "  ì§„í–‰: 100/840 (ë§¤ì¹­: 100, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 200/840 (ë§¤ì¹­: 200, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 300/840 (ë§¤ì¹­: 300, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 400/840 (ë§¤ì¹­: 400, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 500/840 (ë§¤ì¹­: 500, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 600/840 (ë§¤ì¹­: 600, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 700/840 (ë§¤ì¹­: 700, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 800/840 (ë§¤ì¹­: 800, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "  ì§„í–‰: 840/840 (ë§¤ì¹­: 840, ì—†ìŒ: 0, ì‹¤íŒ¨: 0)\n",
      "\n",
      "=== ì»¤ë°‹ ì‹œì‘ ===\n",
      "âœ“ ì»¤ë°‹ ì™„ë£Œ\n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "âœ“ ë§¤ì¹­ ì„±ê³µ: 840ê±´\n",
      "âš  DBì— ì—†ìŒ: 0ê±´\n",
      "âœ— ì˜¤ë¥˜: 0ê±´\n",
      "\n",
      "âœ“ DB ì—°ê²° ì¢…ë£Œ\n",
      "==================================================\n",
      "\n",
      "ì™„ë£Œ! ì´ 840ê±´ ì²˜ë¦¬ë¨\n"
     ]
    }
   ],
   "source": [
    "# drafter, createdAt, activitiesë§Œ UPDATEí•˜ëŠ” ë²„ì „\n",
    "# í…Œì´ë¸” ê¸°ë°˜ ì¶”ì¶œ + CSV ì¡°ì§ë„ ë§¤ì¹­ + ê²°ì¬ì˜ê²¬ ì¶”ê°€ + KST ì‹œê°„ëŒ€ ì²˜ë¦¬\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pytz  # â† ì¶”ê°€\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "class ApprovalDocParser:\n",
    "    def __init__(self, base_path, csv_file):\n",
    "        self.base_path = base_path\n",
    "        self.kst = pytz.timezone('Asia/Seoul')  # â† ì¶”ê°€: í•œêµ­ ì‹œê°„ëŒ€\n",
    "        \n",
    "        # CSV ì¡°ì§ë„ ë¡œë“œ\n",
    "        print(f\"ğŸ“Š CSV ì¡°ì§ë„ ë¡œë“œ ì¤‘... ({csv_file})\")\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8-sig')\n",
    "        self.employee_dict = {}\n",
    "        for _, row in df.iterrows():\n",
    "            self.employee_dict[row['ì‚¬ì›ëª…']] = {\n",
    "                'emailId': row['ID'],\n",
    "                'deptName': row['ë¶€ì„œ'],\n",
    "                'empNo': row['ì‚¬ì›ë²ˆí˜¸'] if pd.notna(row['ì‚¬ì›ë²ˆí˜¸']) else '',\n",
    "                'positionName': row['ì§ìœ„'] if pd.notna(row['ì§ìœ„']) else '',\n",
    "                'deptCode': row['ë¶€ì„œì½”ë“œ'] if pd.notna(row['ë¶€ì„œì½”ë“œ']) else ''\n",
    "            }\n",
    "        print(f\"âœ… ì´ {len(self.employee_dict)}ëª… ë¡œë“œ\\n\")\n",
    "        \n",
    "    def extract_source_id(self, filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ì¶”ì¶œ\"\"\"\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return numbers[-1] if numbers else None\n",
    "    \n",
    "    def extract_person_info(self, text):\n",
    "        \"\"\"ì´ë¦„/ì§ì±…/ë¶€ì„œ í˜•ì‹ì—ì„œ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        text = re.sub(r'\\d+', '', text).strip()\n",
    "        parts = text.split('/')\n",
    "        if len(parts) >= 3:\n",
    "            return {\n",
    "                'name': parts[0].strip(),\n",
    "                'positionName': parts[1].strip(),\n",
    "                'deptName': parts[2].strip()\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def parse_html(self, html_path):\n",
    "        \"\"\"HTML íŒŒì¼ì—ì„œ drafter, createdAt, activitiesë§Œ ì¶”ì¶œ\"\"\"\n",
    "        with open(html_path, 'r', encoding='utf-8') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        filename = os.path.basename(html_path)\n",
    "        source_id = self.extract_source_id(filename)\n",
    "        \n",
    "        # === 1. drafter ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) ===\n",
    "        drafter = {}\n",
    "        drafter_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì' in s)\n",
    "        if drafter_th:\n",
    "            drafter_td = drafter_th.find_next_sibling('td')\n",
    "            if drafter_td:\n",
    "                bg01_div = drafter_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    name = bg01_div.get_text(strip=True)\n",
    "                    if name:\n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': self.employee_dict[name]['positionName'],\n",
    "                                'deptName': self.employee_dict[name]['deptName'],\n",
    "                                'emailId': self.employee_dict[name]['emailId'],\n",
    "                                'deptCode': self.employee_dict[name]['deptCode']\n",
    "                            }\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            drafter = {\n",
    "                                'name': name,\n",
    "                                'positionName': '',\n",
    "                                'deptName': '',\n",
    "                                'emailId': 'master',\n",
    "                                'deptCode': ''\n",
    "                            }\n",
    "        \n",
    "        # === 2. createdAt ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        created_at = None\n",
    "        created_year = None\n",
    "        created_th = soup.find('th', string=lambda s: s and 'ê¸°ì•ˆì¼' in s)\n",
    "        if created_th:\n",
    "            created_td = created_th.find_next_sibling('td')\n",
    "            if created_td:\n",
    "                bg01_div = created_td.find('div', class_='bg01')\n",
    "                if bg01_div:\n",
    "                    date_str = bg01_div.get_text(strip=True)\n",
    "                    try:\n",
    "                        # naive datetime ìƒì„± í›„ KSTë¡œ ëª…ì‹œ\n",
    "                        dt_naive = datetime.strptime(date_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "                        dt_kst = self.kst.localize(dt_naive)\n",
    "                        created_at = int(dt_kst.timestamp() * 1000)\n",
    "                        created_year = dt_kst.year\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # === 3. activities ì¶”ì¶œ (bg02ì—ì„œ) - KST ì²˜ë¦¬ ì¶”ê°€ ===\n",
    "        activities = []\n",
    "        bg02_divs = soup.find_all('div', class_='bg02')\n",
    "        \n",
    "        for idx, bg02 in enumerate(bg02_divs):\n",
    "            ul = bg02.find('ul')\n",
    "            if ul:\n",
    "                lis = ul.find_all('li')\n",
    "                if len(lis) >= 2:\n",
    "                    name = lis[0].get_text(strip=True)\n",
    "                    action_type_text = lis[1].get_text(strip=True)\n",
    "                    date_text = lis[2].get_text(strip=True) if len(lis) >= 3 else ''\n",
    "                    \n",
    "                    if name:\n",
    "                        # íƒ€ì… ê²°ì •\n",
    "                        if 'ê¸°ì•ˆ' in action_type_text:\n",
    "                            action_type = 'DRAFT'\n",
    "                        elif 'í•©ì˜' in action_type_text:\n",
    "                            action_type = 'AGREEMENT'\n",
    "                        else:\n",
    "                            action_type = 'APPROVAL'\n",
    "                        \n",
    "                        # ë‚ ì§œ ë³€í™˜ (00:00:00) - KST ì²˜ë¦¬ ì¶”ê°€\n",
    "                        action_date = None\n",
    "                        if date_text and created_year:\n",
    "                            try:\n",
    "                                full_date = f\"{created_year}-{date_text.replace('/', '-')}\"\n",
    "                                dt_naive = datetime.strptime(full_date, \"%Y-%m-%d\")\n",
    "                                dt_kst = self.kst.localize(dt_naive)\n",
    "                                action_date = int(dt_kst.timestamp() * 1000)\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # CSV ì¡°ì§ë„ ë§¤ì¹­\n",
    "                        if name in self.employee_dict:\n",
    "                            position = self.employee_dict[name]['positionName']\n",
    "                            dept = self.employee_dict[name]['deptName']\n",
    "                            email = self.employee_dict[name]['emailId']\n",
    "                            dept_code = self.employee_dict[name]['deptCode']\n",
    "                        else:\n",
    "                            # í‡´ì‚¬ì\n",
    "                            position = ''\n",
    "                            dept = ''\n",
    "                            email = ''\n",
    "                            dept_code = ''\n",
    "                        \n",
    "                        activities.append({\n",
    "                            'positionName': position,\n",
    "                            'deptName': dept,\n",
    "                            'actionLogType': action_type,\n",
    "                            'name': name,\n",
    "                            'emailId': email,\n",
    "                            'type': action_type,\n",
    "                            'actionDate': action_date,\n",
    "                            'deptCode': dept_code,\n",
    "                            'actionComment': ''  # ì¼ë‹¨ ë¹ˆê°’\n",
    "                        })\n",
    "        \n",
    "        # === 4. actionComment ì¶”ê°€ (user_spansì—ì„œ) ===\n",
    "        user_spans = soup.find_all('span', class_='user')\n",
    "        for user_span in user_spans:\n",
    "            name_elem = user_span.find('span', class_='F_12_black_b')\n",
    "            if name_elem:\n",
    "                info = self.extract_person_info(name_elem.get_text(strip=True))\n",
    "                if info:\n",
    "                    name = info['name']\n",
    "                    \n",
    "                    # ì˜ê²¬ ì¶”ì¶œ - user_spanì˜ ë¶€ëª¨(td)ì—ì„œ div ì°¾ê¸°\n",
    "                    action_comment = \"\"\n",
    "                    parent = user_span.parent\n",
    "                    if parent:\n",
    "                        comment_div = parent.find('div')\n",
    "                        if comment_div:\n",
    "                            action_comment = comment_div.get_text(strip=True)\n",
    "                    \n",
    "                    # activitiesì—ì„œ ì´ë¦„ ì°¾ì•„ì„œ ì˜ê²¬ ì¶”ê°€\n",
    "                    for activity in activities:\n",
    "                        if activity['name'] == name:\n",
    "                            activity['actionComment'] = action_comment\n",
    "                            break\n",
    "        \n",
    "        # ê²°ê³¼ ë°˜í™˜ (í•„ìš”í•œ 3ê°€ì§€ë§Œ)\n",
    "        return {\n",
    "            'sourceId': source_id,\n",
    "            'drafter': drafter,\n",
    "            'createdAt': created_at,\n",
    "            'activities': activities\n",
    "        }\n",
    "    \n",
    "    def process_all_files(self):\n",
    "        \"\"\"ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬\"\"\"\n",
    "        all_results = []\n",
    "        approval_path = Path(self.base_path) / 'ê²°ì¬'\n",
    "        \n",
    "        if not approval_path.exists():\n",
    "            print(f\"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {approval_path}\")\n",
    "            return all_results\n",
    "            \n",
    "        html_files = list(approval_path.rglob('*.html'))\n",
    "        print(f\"ì´ {len(html_files)}ê°œì˜ HTML íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        \n",
    "        for idx, html_file in enumerate(html_files, 1):\n",
    "            try:\n",
    "                if idx % 100 == 0 or idx == len(html_files):\n",
    "                    print(f\"ì²˜ë¦¬ ì¤‘... [{idx}/{len(html_files)}] {html_file.name}\")\n",
    "                result = self.parse_html(html_file)\n",
    "                all_results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"ì˜¤ë¥˜ ë°œìƒ ({html_file.name}): {e}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_to_json(self, data, output_path):\n",
    "        \"\"\"JSON íŒŒì¼ë¡œ ì €ì¥\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
    "    \n",
    "    def save_to_mariadb_update(self, data, db_config, end_year):\n",
    "        \"\"\"MariaDB íŠ¹ì • ì»¬ëŸ¼ë§Œ UPDATE\"\"\"\n",
    "        conn = None\n",
    "        cursor = None\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n=== DB ì—°ê²° ì‹œì‘ ===\")\n",
    "            print(f\"Host: {db_config['host']}, Database: {db_config['database']}\")\n",
    "            \n",
    "            # DB ì—°ê²° - FOUND_ROWS í”Œë˜ê·¸ ì¶”ê°€\n",
    "            conn = pymysql.connect(\n",
    "                host=db_config['host'],\n",
    "                user=db_config['user'],\n",
    "                password=db_config['password'],\n",
    "                database=db_config['database'],\n",
    "                charset='utf8mb4',\n",
    "                client_flag=pymysql.constants.CLIENT.FOUND_ROWS  # â† ì¶”ê°€!\n",
    "            )\n",
    "            print(\"âœ“ DB ì—°ê²° ì„±ê³µ (FOUND_ROWS ëª¨ë“œ)\")\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # UPDATE ì¿¼ë¦¬\n",
    "            update_sql = \"\"\"\n",
    "            UPDATE documents \n",
    "            SET drafter_name = %s,\n",
    "                drafter_position = %s,\n",
    "                drafter_dept = %s,\n",
    "                created_at = %s,\n",
    "                activities = %s\n",
    "            WHERE source_id = %s AND end_year = %s\n",
    "            \"\"\"\n",
    "            \n",
    "            success_count = 0\n",
    "            not_found_count = 0\n",
    "            error_count = 0\n",
    "            error_details = []\n",
    "            not_found_ids = []\n",
    "            \n",
    "            print(f\"\\n=== ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œì‘ ({len(data)}ê±´) ===\")\n",
    "            \n",
    "            for idx, doc in enumerate(data, 1):\n",
    "                try:\n",
    "                    def safe_json(value):\n",
    "                        if not value:\n",
    "                            return '[]'\n",
    "                        try:\n",
    "                            return json.dumps(value, ensure_ascii=False)\n",
    "                        except:\n",
    "                            return '[]'\n",
    "                    \n",
    "                    source_id = doc.get('sourceId')\n",
    "                    \n",
    "                    values = (\n",
    "                        doc.get('drafter', {}).get('name', ''),\n",
    "                        doc.get('drafter', {}).get('positionName', ''),\n",
    "                        doc.get('drafter', {}).get('deptName', ''),\n",
    "                        doc.get('createdAt'),\n",
    "                        safe_json(doc.get('activities', [])),\n",
    "                        source_id,\n",
    "                        end_year\n",
    "                    )\n",
    "                    \n",
    "                    cursor.execute(update_sql, values)\n",
    "                    \n",
    "                    # FOUND_ROWS ëª¨ë“œ: ë§¤ì¹­ëœ í–‰ ìˆ˜ ë°˜í™˜ (ë³€ê²½ ì—¬ë¶€ ë¬´ê´€)\n",
    "                    if cursor.rowcount > 0:\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        not_found_count += 1\n",
    "                        not_found_ids.append(source_id)\n",
    "                    \n",
    "                    if idx % 100 == 0 or idx == len(data):\n",
    "                        print(f\"  ì§„í–‰: {idx}/{len(data)} (ë§¤ì¹­: {success_count}, ì—†ìŒ: {not_found_count}, ì‹¤íŒ¨: {error_count})\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    error_msg = f\"sourceId: {doc.get('sourceId')} - {str(e)[:80]}\"\n",
    "                    error_details.append(error_msg)\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"  [ì˜¤ë¥˜ {error_count}] {error_msg}\")\n",
    "            \n",
    "            print(\"\\n=== ì»¤ë°‹ ì‹œì‘ ===\")\n",
    "            conn.commit()\n",
    "            print(\"âœ“ ì»¤ë°‹ ì™„ë£Œ\")\n",
    "            \n",
    "            print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "            print(f\"âœ“ ë§¤ì¹­ ì„±ê³µ: {success_count}ê±´\")\n",
    "            print(f\"âš  DBì— ì—†ìŒ: {not_found_count}ê±´\")\n",
    "            print(f\"âœ— ì˜¤ë¥˜: {error_count}ê±´\")\n",
    "            \n",
    "            if not_found_ids:\n",
    "                print(f\"\\nâš  DBì—ì„œ ëª» ì°¾ì€ source_id ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):\")\n",
    "                for nf_id in not_found_ids[:20]:\n",
    "                    print(f\"  - {nf_id}\")\n",
    "                \n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT MIN(source_id), MAX(source_id) \n",
    "                    FROM documents \n",
    "                    WHERE end_year = %s\n",
    "                \"\"\", (end_year,))\n",
    "                min_id, max_id = cursor.fetchone()\n",
    "                print(f\"\\nğŸ“Š DBì˜ source_id ë²”ìœ„: {min_id} ~ {max_id}\")\n",
    "            \n",
    "            if error_count > 5:\n",
    "                print(f\"\\nì²˜ìŒ 5ê°œ ì™¸ {error_count - 5}ê°œì˜ ì¶”ê°€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "                print(\"ëª¨ë“  ì˜¤ë¥˜ ë³´ê¸°:\")\n",
    "                for err in error_details[:20]:\n",
    "                    print(f\"  - {err}\")\n",
    "                if len(error_details) > 20:\n",
    "                    print(f\"  ... ì™¸ {len(error_details) - 20}ê°œ ë”\")\n",
    "            \n",
    "        except pymysql.Error as e:\n",
    "            print(f\"\\nâŒ DB ì˜¤ë¥˜ ë°œìƒ:\")\n",
    "            print(f\"  Error Code: {e.args[0]}\")\n",
    "            print(f\"  Error Message: {e.args[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ì¼ë°˜ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            if cursor:\n",
    "                cursor.close()\n",
    "            if conn:\n",
    "                conn.close()\n",
    "                print(\"\\nâœ“ DB ì—°ê²° ì¢…ë£Œ\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_path = r'C:\\Users\\LEEJUHWAN\\Downloads\\2011-01-01~2015-12-31\\html'\n",
    "    end_year = 2015\n",
    "    csv_file = 'ì¸ì‚¬ì •ë³´_ë¶€ì„œì½”ë“œì¶”ê°€.csv'\n",
    "    \n",
    "    parser = ApprovalDocParser(base_path, csv_file)\n",
    "    \n",
    "    print(\"HTML íŒŒì¼ íŒŒì‹± ì‹œì‘...\")\n",
    "    results = parser.process_all_files()\n",
    "    \n",
    "    output_json_path = 'update_drafter_activities.json'\n",
    "    parser.save_to_json(results, output_json_path)\n",
    "    \n",
    "    db_config = {\n",
    "        'host': 'localhost',\n",
    "        'user': 'root',\n",
    "        'password': '1234',\n",
    "        'database': 'any_approval'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    parser.save_to_mariadb_update(results, db_config, end_year)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nì™„ë£Œ! ì´ {len(results)}ê±´ ì²˜ë¦¬ë¨\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
